{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b0f0f4f3",
   "metadata": {},
   "source": [
    "# Import packages & functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5bad764b-45c1-45ce-a716-8d055e09821a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/admin/home-conscioustahoe/miniconda3/envs/fmri2/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "no module 'xformers'. Processing without...\n",
      "no module 'xformers'. Processing without...\n",
      "no module 'xformers'. Processing without...\n",
      "no module 'xformers'. Processing without...\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import argparse\n",
    "import numpy as np\n",
    "import math\n",
    "from einops import rearrange\n",
    "import time\n",
    "import random\n",
    "import string\n",
    "import h5py\n",
    "from tqdm import tqdm\n",
    "import webdataset as wds\n",
    "import gc\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "from accelerate import Accelerator, DeepSpeedPlugin\n",
    "\n",
    "# # SDXL unCLIP requires code from https://github.com/Stability-AI/generative-models/tree/main\n",
    "sys.path.append('generative_models/')\n",
    "import sgm\n",
    "from generative_models.sgm.modules.encoders.modules import FrozenOpenCLIPImageEmbedder\n",
    "from generative_models.sgm.models.diffusion import DiffusionEngine\n",
    "from omegaconf import OmegaConf\n",
    "\n",
    "# tf32 data type is faster than standard float32\n",
    "torch.backends.cuda.matmul.allow_tf32 = True\n",
    "\n",
    "# custom functions #\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc5d2e32-6027-4a19-bef4-5ca068db35bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOCAL RANK  0\n",
      "[2024-01-22 20:52:23,088] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "Setting batch_size to 16\n",
      "[2024-01-22 20:52:26,659] [INFO] [comm.py:637:init_distributed] cdb=None\n",
      "[2024-01-22 20:52:26,659] [INFO] [comm.py:668:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl\n"
     ]
    }
   ],
   "source": [
    "### Multi-GPU config ###\n",
    "local_rank = os.getenv('RANK')\n",
    "if local_rank is None: \n",
    "    local_rank = 0\n",
    "else:\n",
    "    local_rank = int(local_rank)\n",
    "print(\"LOCAL RANK \", local_rank)  \n",
    "\n",
    "data_type = torch.float16 # change depending on your mixed_precision\n",
    "\n",
    "# ## IF NOT USING DEEPSPEED ###\n",
    "# use_deepspeed = False\n",
    "# accelerator = Accelerator(split_batches=False, mixed_precision=\"fp16\") # ['no', 'fp8', 'fp16', 'bf16']\n",
    "# global_batch_size = batch_size = 8\n",
    "\n",
    "### DEEPSPEED INITIALIZATION ###\n",
    "os.environ['DS_SKIP_CUDA_CHECK'] = '1'\n",
    "use_deepspeed = True\n",
    "import deepspeed\n",
    "num_devices = torch.cuda.device_count()\n",
    "if num_devices==0: num_devices = 1\n",
    "if num_devices <= 1 and utils.is_interactive():\n",
    "    global_batch_size = batch_size = 16\n",
    "    print(f\"Setting batch_size to {batch_size}\")\n",
    "    # can emulate a distributed environment for deepspeed to work in jupyter notebook\n",
    "    os.environ[\"MASTER_ADDR\"] = \"localhost\"\n",
    "    os.environ[\"MASTER_PORT\"] = str(np.random.randint(10000)+9000)\n",
    "    os.environ[\"RANK\"] = \"0\"\n",
    "    os.environ[\"LOCAL_RANK\"] = \"0\"\n",
    "    os.environ[\"WORLD_SIZE\"] = \"1\"\n",
    "    os.environ[\"GLOBAL_BATCH_SIZE\"] = str(global_batch_size) # set this to your batch size!\n",
    "else:\n",
    "    global_batch_size = os.environ[\"GLOBAL_BATCH_SIZE\"]    \n",
    "    batch_size = int(os.environ[\"GLOBAL_BATCH_SIZE\"]) // num_devices\n",
    "    if num_devices <= 1:\n",
    "        os.environ[\"RANK\"] = \"0\"\n",
    "        os.environ[\"LOCAL_RANK\"] = \"0\"\n",
    "        os.environ[\"WORLD_SIZE\"] = \"1\"\n",
    "\n",
    "# alter the deepspeed config according to your global and local batch size\n",
    "if local_rank == 0:\n",
    "    with open('deepspeed_config_stage2_cpuoffload.json', 'r') as file:\n",
    "        config = json.load(file)\n",
    "    config['train_batch_size'] = int(os.environ[\"GLOBAL_BATCH_SIZE\"])\n",
    "    config['train_micro_batch_size_per_gpu'] = batch_size\n",
    "    config['bf16'] = {'enabled': False}\n",
    "    config['fp16'] = {'enabled': True}\n",
    "    with open('deepspeed_config_stage2_cpuoffload.json', 'w') as file:\n",
    "        json.dump(config, file)\n",
    "else:\n",
    "    # give some time for the local_rank=0 gpu to prep new deepspeed config file\n",
    "    time.sleep(10)\n",
    "deepspeed_plugin = DeepSpeedPlugin(\"deepspeed_config_stage2_cpuoffload.json\")\n",
    "accelerator = Accelerator(split_batches=False, deepspeed_plugin=deepspeed_plugin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b767ab6f-d4a9-47a5-b3bf-f56bf6760c0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PID of this process = 263853\n",
      "device: cuda:0\n",
      "Distributed environment: DistributedType.DEEPSPEED  Backend: nccl\n",
      "Num processes: 1\n",
      "Process index: 0\n",
      "Local process index: 0\n",
      "Device: cuda:0\n",
      "\n",
      "Mixed precision type: fp16\n",
      "ds_config: {'bf16': {'enabled': False}, 'fp16': {'enabled': True}, 'zero_optimization': {'stage': 2, 'contiguous_gradients': True, 'stage3_gather_16bit_weights_on_model_save': True, 'stage3_max_live_parameters': 1000000000.0, 'stage3_max_reuse_distance': 1000000000.0, 'stage3_prefetch_bucket_size': 10000000.0, 'stage3_param_persistence_threshold': 100000.0, 'reduce_bucket_size': 10000000.0, 'sub_group_size': 1000000000.0, 'offload_optimizer': {'device': 'cpu', 'nvme_path': '/scratch', 'pin_memory': True}, 'offload_param': {'device': 'none', 'nvme_path': '/scratch', 'buffer_size': 4000000000.0, 'pin_memory': True}}, 'aio': {'block_size': 26214400, 'queue_depth': 32, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}, 'gradient_accumulation_steps': 1, 'gradient_clipping': 1.0, 'steps_per_print': inf, 'train_batch_size': 16, 'train_micro_batch_size_per_gpu': 16, 'wall_clock_breakdown': False, 'zero_allow_untested_optimizer': True}\n",
      "\n",
      "distributed = True num_devices = 1 local rank = 0 world size = 1 data_type = torch.float16\n"
     ]
    }
   ],
   "source": [
    "print(\"PID of this process =\",os.getpid())\n",
    "device = accelerator.device\n",
    "print(\"device:\",device)\n",
    "world_size = accelerator.state.num_processes\n",
    "distributed = not accelerator.state.distributed_type == 'NO'\n",
    "num_devices = torch.cuda.device_count()\n",
    "if num_devices==0 or not distributed: num_devices = 1\n",
    "num_workers = num_devices\n",
    "print(accelerator.state)\n",
    "\n",
    "# set data_type to match your mixed precision (automatically set based on deepspeed config)\n",
    "if accelerator.mixed_precision == \"bf16\":\n",
    "    data_type = torch.bfloat16\n",
    "elif accelerator.mixed_precision == \"fp16\":\n",
    "    data_type = torch.float16\n",
    "else:\n",
    "    data_type = torch.float32\n",
    "\n",
    "print(\"distributed =\",distributed, \"num_devices =\", num_devices, \"local rank =\", local_rank, \"world size =\", world_size, \"data_type =\", data_type)\n",
    "print = accelerator.print # only print if local_rank=0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9018b82b-c054-4463-9527-4b0c2a75bda6",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2b61fec7-72a0-4b67-86da-1375f1d9fbd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_name: testing\n",
      "--data_path=/weka/proj-fmri/shared/mindeyev2_dataset                     --model_name=testing                     --no-multi_subject --subj=1 --batch_size=16 --num_sessions=10                     --hidden_dim=1024 --clip_scale=1.                     --blurry_recon --blur_scale=.5                      --seq_past=0 --seq_future=0                     --use_prior --prior_scale=30 --no-visualize_prior                     --n_blocks=4 --max_lr=3e-4 --mixup_pct=.33 --num_epochs=50 --no-use_image_aug                     --ckpt_interval=1 --no-wandb_log\n"
     ]
    }
   ],
   "source": [
    "# if running this interactively, can specify jupyter_args here for argparser to use\n",
    "if utils.is_interactive():\n",
    "    model_name = \"testing\"\n",
    "    print(\"model_name:\", model_name)\n",
    "    \n",
    "    # global_batch_size and batch_size should already be defined in the above cells\n",
    "    # other variables can be specified in the following string:\n",
    "    jupyter_args = f\"--data_path=/weka/proj-fmri/shared/mindeyev2_dataset \\\n",
    "                    --model_name={model_name} \\\n",
    "                    --no-multi_subject --subj=1 --batch_size={batch_size} --num_sessions=10 \\\n",
    "                    --hidden_dim=1024 --clip_scale=1. \\\n",
    "                    --blurry_recon --blur_scale=.5  \\\n",
    "                    --seq_past=0 --seq_future=0 \\\n",
    "                    --use_prior --prior_scale=30 --no-visualize_prior \\\n",
    "                    --n_blocks=4 --max_lr=3e-4 --mixup_pct=.33 --num_epochs=50 --no-use_image_aug \\\n",
    "                    --ckpt_interval=1 --no-wandb_log\"# \\\n",
    "                    # --multisubject_ckpt=../train_logs/multisubject_150ep_4block_hid4096_bs64\" \n",
    "\n",
    "    print(jupyter_args)\n",
    "    jupyter_args = jupyter_args.split()\n",
    "    \n",
    "    from IPython.display import clear_output # function to clear print outputs in cell\n",
    "    %load_ext autoreload \n",
    "    # this allows you to change functions in models.py or utils.py and have this notebook automatically update with your revisions\n",
    "    %autoreload 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2028bdf0-2f41-46d9-b6e7-86b870dbf16c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subj_list [1] num_sessions 10\n"
     ]
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser(description=\"Model Training Configuration\")\n",
    "parser.add_argument(\n",
    "    \"--model_name\", type=str, default=\"testing\",\n",
    "    help=\"name of model, used for ckpt saving and wandb logging (if enabled)\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--data_path\", type=str, default=\"/weka/proj-fmri/shared/natural-scenes-dataset\",\n",
    "    help=\"Path to where NSD data is stored / where to download it to\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--subj\",type=int, default=1, choices=[1,2,3,4,5,6,7,8],\n",
    "    help=\"Validate on which subject?\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--multisubject_ckpt\", type=str, default=None,\n",
    "    help=\"Path to pre-trained multisubject model to finetune a single subject from. multisubject must be False.\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--num_sessions\", type=int, default=0,\n",
    "    help=\"Number of training sessions to include (zero = all sessions)\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--use_prior\",action=argparse.BooleanOptionalAction,default=True,\n",
    "    help=\"whether to train diffusion prior (True) or just rely on retrieval part of the pipeline (False)\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--visualize_prior\",action=argparse.BooleanOptionalAction,default=False,\n",
    "    help=\"output visualizations from unCLIP every ckpt_interval (requires more memory!)\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--batch_size\", type=int, default=16,\n",
    "    help=\"Batch size can be increased by 10x if only training retreival submodule and not diffusion prior\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--wandb_log\",action=argparse.BooleanOptionalAction,default=False,\n",
    "    help=\"whether to log to wandb\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--resume_from_ckpt\",action=argparse.BooleanOptionalAction,default=False,\n",
    "    help=\"if not using wandb and want to resume from a ckpt\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--wandb_project\",type=str,default=\"stability\",\n",
    "    help=\"wandb project name\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--mixup_pct\",type=float,default=.33,\n",
    "    help=\"proportion of way through training when to switch from BiMixCo to SoftCLIP\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--blurry_recon\",action=argparse.BooleanOptionalAction,default=True,\n",
    "    help=\"whether to output blurry reconstructions\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--blur_scale\",type=float,default=.5,\n",
    "    help=\"multiply loss from blurry recons by this number\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--clip_scale\",type=float,default=1.,\n",
    "    help=\"multiply contrastive loss by this number\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--prior_scale\",type=float,default=30,\n",
    "    help=\"multiply diffusion prior loss by this\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--use_image_aug\",action=argparse.BooleanOptionalAction,default=False,\n",
    "    help=\"whether to use image augmentation\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--num_epochs\",type=int,default=150,\n",
    "    help=\"number of epochs of training\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--multi_subject\",action=argparse.BooleanOptionalAction,default=False,\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--new_test\",action=argparse.BooleanOptionalAction,default=True,\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--n_blocks\",type=int,default=4,\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--hidden_dim\",type=int,default=1024,\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--seq_past\",type=int,default=0,\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--seq_future\",type=int,default=0,\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--lr_scheduler_type\",type=str,default='cycle',choices=['cycle','linear'],\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--ckpt_saving\",action=argparse.BooleanOptionalAction,default=True,\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--ckpt_interval\",type=int,default=5,\n",
    "    help=\"save backup ckpt and reconstruct every x epochs\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--seed\",type=int,default=42,\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--max_lr\",type=float,default=3e-4,\n",
    ")\n",
    "\n",
    "if utils.is_interactive():\n",
    "    args = parser.parse_args(jupyter_args)\n",
    "else:\n",
    "    args = parser.parse_args()\n",
    "\n",
    "# create global variables without the args prefix\n",
    "for attribute_name in vars(args).keys():\n",
    "    globals()[attribute_name] = getattr(args, attribute_name)\n",
    "    \n",
    "# seed all random functions\n",
    "utils.seed_everything(seed)\n",
    "\n",
    "outdir = os.path.abspath(f'../train_logs/{model_name}')\n",
    "if not os.path.exists(outdir) and ckpt_saving:\n",
    "    os.makedirs(outdir,exist_ok=True)\n",
    "    \n",
    "if use_image_aug or blurry_recon:\n",
    "    import kornia\n",
    "    from kornia.augmentation.container import AugmentationSequential\n",
    "if use_image_aug:\n",
    "    img_augment = AugmentationSequential(\n",
    "        kornia.augmentation.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.4, hue=0.1, p=0.3),\n",
    "        same_on_batch=False,\n",
    "        data_keys=[\"input\"],\n",
    "    )\n",
    "    \n",
    "if multi_subject:\n",
    "    subj_list = np.arange(1,9)\n",
    "    subj_list = subj_list[subj_list != subj]\n",
    "else:\n",
    "    subj_list = [subj]\n",
    "\n",
    "print(\"subj_list\", subj_list, \"num_sessions\", num_sessions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42d13c25-1369-4c49-81d4-83d713586096",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Prep data, models, and dataloaders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c023f24-5233-4a15-a2f5-78487b3a8546",
   "metadata": {},
   "source": [
    "### Creating wds dataloader, preload betas and all 73k possible images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aefe7c27-ab39-4b2c-90f4-480f4087b7ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dividing batch size by subj_list, which will then be concatenated across subj during training...\n",
      "batch_size = 16 num_iterations_per_epoch = 468 num_samples_per_epoch = 7500\n"
     ]
    }
   ],
   "source": [
    "def my_split_by_node(urls): return urls\n",
    "num_voxels_list = []\n",
    "\n",
    "if multi_subject:\n",
    "    nsessions_allsubj=np.array([40, 40, 32, 30, 40, 32, 40, 30])\n",
    "    num_samples_per_epoch = (750*40) // num_devices \n",
    "else:\n",
    "    num_samples_per_epoch = (750*num_sessions) // num_devices \n",
    "\n",
    "print(\"dividing batch size by subj_list, which will then be concatenated across subj during training...\") \n",
    "batch_size = batch_size // len(subj_list)\n",
    "\n",
    "num_iterations_per_epoch = num_samples_per_epoch // (batch_size*len(subj_list))\n",
    "\n",
    "print(\"batch_size =\", batch_size, \"num_iterations_per_epoch =\",num_iterations_per_epoch, \"num_samples_per_epoch =\",num_samples_per_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "81084834-035f-4465-ad59-59e6b806a2f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with 10 sessions\n",
      "/weka/proj-fmri/shared/mindeyev2_dataset/wds/subj01/train/{0..9}.tar\n",
      "num_voxels for subj01: 15724\n",
      "Loaded all subj train dls and betas!\n",
      "\n",
      "/weka/proj-fmri/shared/mindeyev2_dataset/wds/subj01/new_test/0.tar\n",
      "Loaded test dl for subj1!\n",
      "\n",
      "currently using 1 seq_len (chose 0 past behav and 0 future behav)\n"
     ]
    }
   ],
   "source": [
    "train_data = {}\n",
    "train_dl = {}\n",
    "num_voxels = {}\n",
    "voxels = {}\n",
    "for s in subj_list:\n",
    "    print(f\"Training with {num_sessions} sessions\")\n",
    "    if multi_subject:\n",
    "        train_url = f\"{data_path}/wds/subj0{s}/train/\" + \"{0..\" + f\"{nsessions_allsubj[s-1]-1}\" + \"}.tar\"\n",
    "    else:\n",
    "        train_url = f\"{data_path}/wds/subj0{s}/train/\" + \"{0..\" + f\"{num_sessions-1}\" + \"}.tar\"\n",
    "    print(train_url)\n",
    "    \n",
    "    train_data[f'subj0{s}'] = wds.WebDataset(train_url,resampled=True,nodesplitter=my_split_by_node)\\\n",
    "                        .shuffle(750, initial=1500, rng=random.Random(42))\\\n",
    "                        .decode(\"torch\")\\\n",
    "                        .rename(behav=\"behav.npy\", past_behav=\"past_behav.npy\", future_behav=\"future_behav.npy\", olds_behav=\"olds_behav.npy\")\\\n",
    "                        .to_tuple(*[\"behav\", \"past_behav\", \"future_behav\", \"olds_behav\"])\n",
    "    train_dl[f'subj0{s}'] = torch.utils.data.DataLoader(train_data[f'subj0{s}'], batch_size=batch_size, shuffle=False, drop_last=True, pin_memory=True)\n",
    "\n",
    "    # Load hdf5 data for betas, but don't put everything into memory\n",
    "    f = h5py.File(f'{data_path}/betas_all_subj0{s}_fp32_renorm.hdf5', 'r')\n",
    "    \n",
    "    betas = f['betas'][:]\n",
    "    betas = torch.Tensor(betas).to(\"cpu\").to(data_type)\n",
    "    num_voxels_list.append(betas[0].shape[-1])\n",
    "    num_voxels[f'subj0{s}'] = betas[0].shape[-1]\n",
    "    voxels[f'subj0{s}'] = betas\n",
    "    print(f\"num_voxels for subj0{s}: {num_voxels[f'subj0{s}']}\")\n",
    "\n",
    "print(\"Loaded all subj train dls and betas!\\n\")\n",
    "\n",
    "# Validate only on one subject\n",
    "if multi_subject: \n",
    "    subj = subj_list[0] # cant validate on the actual held out person so picking first in subj_list\n",
    "if not new_test: # using old test set from before full dataset released (used in original MindEye paper)\n",
    "    if subj==3:\n",
    "        num_test=2113\n",
    "    elif subj==4:\n",
    "        num_test=1985\n",
    "    elif subj==6:\n",
    "        num_test=2113\n",
    "    elif subj==8:\n",
    "        num_test=1985\n",
    "    else:\n",
    "        num_test=2770\n",
    "    test_url = f\"{data_path}/wds/subj0{subj}/test/\" + \"0.tar\"\n",
    "elif new_test: # using larger test set from after full dataset released\n",
    "    if subj==3:\n",
    "        num_test=2371\n",
    "    elif subj==4:\n",
    "        num_test=2188\n",
    "    elif subj==6:\n",
    "        num_test=2371\n",
    "    elif subj==8:\n",
    "        num_test=2188\n",
    "    else:\n",
    "        num_test=3000\n",
    "    test_url = f\"{data_path}/wds/subj0{subj}/new_test/\" + \"0.tar\"\n",
    "print(test_url)\n",
    "test_data = wds.WebDataset(test_url,resampled=False,nodesplitter=my_split_by_node)\\\n",
    "                    .shuffle(750, initial=1500, rng=random.Random(42))\\\n",
    "                    .decode(\"torch\")\\\n",
    "                    .rename(behav=\"behav.npy\", past_behav=\"past_behav.npy\", future_behav=\"future_behav.npy\", olds_behav=\"olds_behav.npy\")\\\n",
    "                    .to_tuple(*[\"behav\", \"past_behav\", \"future_behav\", \"olds_behav\"])\n",
    "test_dl = torch.utils.data.DataLoader(test_data, batch_size=num_test, shuffle=False, drop_last=True, pin_memory=True)\n",
    "print(f\"Loaded test dl for subj{subj}!\\n\")\n",
    "\n",
    "seq_len = seq_past + 1 + seq_future\n",
    "print(f\"currently using {seq_len} seq_len (chose {seq_past} past behav and {seq_future} future behav)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c13b4b84-094c-4b5b-bace-26c155aa6181",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded all 73k possible NSD images to cpu! torch.Size([73000, 3, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "# Load 73k NSD images\n",
    "f = h5py.File(f'{data_path}/coco_images_224_float16.hdf5', 'r')\n",
    "images = f['images'][:]\n",
    "images = torch.Tensor(images).to(\"cpu\").to(data_type)\n",
    "print(\"Loaded all 73k possible NSD images to cpu!\", images.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10ec4517-dbdf-4ece-98f6-4714d5de4e15",
   "metadata": {},
   "source": [
    "## Load models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48d6160e-1ee8-4da7-a755-9dbb452a6fa5",
   "metadata": {},
   "source": [
    "### CLIP image embeddings  model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b0420dc0-199e-4c1a-857d-b1747058b467",
   "metadata": {},
   "outputs": [],
   "source": [
    "clip_img_embedder = FrozenOpenCLIPImageEmbedder(\n",
    "    arch=\"ViT-bigG-14\",\n",
    "    version=\"laion2b_s39b_b160k\",\n",
    "    output_tokens=True,\n",
    "    only_tokens=True,\n",
    ")\n",
    "clip_img_embedder.to(device)\n",
    "\n",
    "clip_seq_dim = 256\n",
    "clip_emb_dim = 1664"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b79bd38-6990-4504-8d45-4a68d57d8885",
   "metadata": {},
   "source": [
    "### SD VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "01baff79-8114-482b-b115-6f05aa8ad691",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param counts:\n",
      "83,653,863 total\n",
      "0 trainable\n"
     ]
    }
   ],
   "source": [
    "if blurry_recon:\n",
    "    from diffusers import AutoencoderKL\n",
    "    # autoenc = AutoencoderKL.from_pretrained(\"madebyollin/sdxl-vae-fp16-fix\", torch_dtype=torch.float16, cache_dir=\"/weka/proj-fmri/shared/cache\")\n",
    "    # autoenc = AutoencoderKL.from_pretrained(\"stabilityai/sd-vae-ft-mse\", torch_dtype=torch.float16, cache_dir=\"/weka/proj-fmri/shared/cache\")\n",
    "    \n",
    "    autoenc = AutoencoderKL(\n",
    "        down_block_types=['DownEncoderBlock2D', 'DownEncoderBlock2D', 'DownEncoderBlock2D', 'DownEncoderBlock2D'],\n",
    "        up_block_types=['UpDecoderBlock2D', 'UpDecoderBlock2D', 'UpDecoderBlock2D', 'UpDecoderBlock2D'],\n",
    "        block_out_channels=[128, 256, 512, 512],\n",
    "        layers_per_block=2,\n",
    "        sample_size=256,\n",
    "    )\n",
    "    ckpt = torch.load('/weka/proj-fmri/shared/cache/sd_var_enc/sd_image_var_autoenc.pth')\n",
    "    autoenc.load_state_dict(ckpt)\n",
    "    \n",
    "    autoenc.eval()\n",
    "    autoenc.requires_grad_(False)\n",
    "    autoenc.to(device)\n",
    "    utils.count_params(autoenc)\n",
    "    \n",
    "    from autoencoder.convnext import ConvnextXL\n",
    "    cnx = ConvnextXL('/weka/proj-fmri/shared/cache/convnextv2/convnext_xlarge_alpha0.75_fullckpt.pth')\n",
    "    cnx.requires_grad_(False)\n",
    "    cnx.eval()\n",
    "    cnx.to(device)\n",
    "    \n",
    "    mean = torch.tensor([0.485, 0.456, 0.406]).to(device).reshape(1,3,1,1)\n",
    "    std = torch.tensor([0.228, 0.224, 0.225]).to(device).reshape(1,3,1,1)\n",
    "    \n",
    "    blur_augs = AugmentationSequential(\n",
    "        kornia.augmentation.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.2, hue=0.1, p=0.8),\n",
    "        kornia.augmentation.RandomGrayscale(p=0.1),\n",
    "        kornia.augmentation.RandomSolarize(p=0.1),\n",
    "        kornia.augmentation.RandomResizedCrop((224,224), scale=(.9,.9), ratio=(1,1), p=1.0),\n",
    "        data_keys=[\"input\"],\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "260e5e4a-f697-4b2c-88fc-01f6a54886c0",
   "metadata": {},
   "source": [
    "### MindEye modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c44c271b-173f-472e-b059-a2eda0f4c4c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MindEyeModule()"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class MindEyeModule(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MindEyeModule, self).__init__()\n",
    "    def forward(self, x):\n",
    "        return x\n",
    "        \n",
    "model = MindEyeModule()\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "038a5d61-4769-40b9-a004-f4e7b5b38bb0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# class RidgeRegression(torch.nn.Module):\n",
    "#     # make sure to add weight_decay when initializing optimizer\n",
    "#     def __init__(self, input_sizes, out_features, seq_len): \n",
    "#         super(RidgeRegression, self).__init__()\n",
    "#         self.out_features = out_features\n",
    "#         self.linears = torch.nn.ModuleList([\n",
    "#                 torch.nn.Linear(input_size, out_features) for input_size in input_sizes\n",
    "#             ])\n",
    "#     def forward(self, x, subj_idx):\n",
    "#         out = torch.cat([self.linears[subj_idx](x[:,seq]).unsqueeze(1) for seq in range(seq_len)], dim=1)\n",
    "#         return out\n",
    "        \n",
    "# model.ridge = RidgeRegression(num_voxels_list, out_features=hidden_dim, seq_len=seq_len)\n",
    "# utils.count_params(model.ridge)\n",
    "# utils.count_params(model)\n",
    "\n",
    "# # test on subject 1 with fake data\n",
    "# b = torch.randn((2,seq_len,num_voxels_list[0]))\n",
    "# print(b.shape, model.ridge(b,0).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4aaa85b2-6aec-41a9-84cd-e94ac4fbd8b0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'subj01': 15724}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_voxels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c2599d-9b40-4d42-b311-c1b5f5443258",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7d5c861e-63bb-4dce-9ce6-0bd92a3561b2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d270860a-b9b0-4b3b-9588-346d368f45de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param counts:\n",
      "473,495,780 total\n",
      "473,495,780 trainable\n",
      "param counts:\n",
      "473,495,780 total\n",
      "473,495,780 trainable\n",
      "b.shape torch.Size([2, 15724])\n",
      "torch.Size([2, 256, 1664]) torch.Size([2, 256, 1664]) torch.Size([2, 4, 28, 28]) torch.Size([2, 49, 512])\n"
     ]
    }
   ],
   "source": [
    "from functools import partial\n",
    "from diffusers.models.vae import Decoder\n",
    "class BrainNetwork(nn.Module):\n",
    "    def __init__(self, out_dim=257*768, in_dim=15724, clip_size=768, h=4096):\n",
    "        super().__init__()\n",
    "        self.clip_size = clip_size\n",
    "        self.lin0 = nn.Sequential(\n",
    "            nn.Linear(in_dim, h, bias=False),\n",
    "            nn.LayerNorm(h),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(0.5))\n",
    "        self.mlp = nn.ModuleList([\n",
    "            nn.Sequential(\n",
    "                nn.Linear(h, h),\n",
    "                nn.LayerNorm(h),\n",
    "                nn.GELU(),\n",
    "                nn.Dropout(0.15)\n",
    "            ) for _ in range(4)])\n",
    "        self.lin1 = nn.Linear(h, out_dim, bias=True)\n",
    "        self.proj = nn.Sequential(\n",
    "            nn.LayerNorm(clip_size),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(clip_size, 2048),\n",
    "            nn.LayerNorm(2048),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(2048, 2048),\n",
    "            nn.LayerNorm(2048),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(2048, clip_size))\n",
    "\n",
    "        if blurry_recon:\n",
    "            self.blin1 = nn.Linear(h,4*28*28,bias=True)\n",
    "            self.bdropout = nn.Dropout(.3)\n",
    "            self.bnorm = nn.GroupNorm(1, 64)\n",
    "            self.bupsampler = Decoder(\n",
    "                in_channels=64,\n",
    "                out_channels=4,\n",
    "                up_block_types=[\"UpDecoderBlock2D\",\"UpDecoderBlock2D\",\"UpDecoderBlock2D\"],\n",
    "                block_out_channels=[32, 64, 128],\n",
    "                layers_per_block=1,\n",
    "            )\n",
    "            self.b_maps_projector = nn.Sequential(\n",
    "                nn.Conv2d(64, 512, 1, bias=False),\n",
    "                nn.GroupNorm(1,512),\n",
    "                nn.ReLU(True),\n",
    "                nn.Conv2d(512, 512, 1, bias=False),\n",
    "                nn.GroupNorm(1,512),\n",
    "                nn.ReLU(True),\n",
    "                nn.Conv2d(512, 512, 1, bias=True),\n",
    "            )        \n",
    "    def forward(self, x):\n",
    "        x = self.lin0(x)\n",
    "        residual = x\n",
    "        for res_block in range(n_blocks):\n",
    "            x = self.mlp[res_block](x)\n",
    "            x += residual\n",
    "            residual = x\n",
    "        diffusion_prior_input = self.lin1(x.reshape(len(x), -1))\n",
    "        disjointed_clip_fmri = self.proj(diffusion_prior_input.reshape(\n",
    "                                        len(x),-1, self.clip_size))        \n",
    "        diffusion_prior_input = diffusion_prior_input.reshape(len(x), 256, self.clip_size)\n",
    "        if blurry_recon:\n",
    "            b = self.blin1(x)\n",
    "            b = self.bdropout(b)\n",
    "            b = b.reshape(b.shape[0], -1, 7, 7).contiguous()\n",
    "            b = self.bnorm(b)\n",
    "            b_aux = self.b_maps_projector(b).flatten(2).permute(0,2,1)\n",
    "            b_aux = b_aux.view(len(b_aux), 49, 512)\n",
    "            b = (self.bupsampler(b), b_aux)\n",
    "            \n",
    "        return disjointed_clip_fmri, diffusion_prior_input, b\n",
    "\n",
    "model.backbone = BrainNetwork(out_dim=clip_emb_dim*clip_seq_dim, in_dim=15724, \n",
    "                          clip_size=clip_emb_dim, h=hidden_dim)\n",
    "utils.count_params(model.backbone)\n",
    "utils.count_params(model)\n",
    "\n",
    "# test that the model works on some fake data\n",
    "b = torch.randn((2, 15724))\n",
    "print(\"b.shape\",b.shape)\n",
    "\n",
    "backbone_, clip_, blur_ = model.backbone(b)\n",
    "print(backbone_.shape, clip_.shape, blur_[0].shape, blur_[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7b8de65a-6d3b-4248-bea9-9b6f4d562321",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from functools import partial\n",
    "# from diffusers.models.vae import Decoder\n",
    "# class BrainNetwork(nn.Module):\n",
    "#     def __init__(self, h=4096, in_dim=15724, out_dim=768, seq_len=2, n_blocks=n_blocks, drop=.15, \n",
    "#                  clip_size=768):\n",
    "#         super().__init__()\n",
    "#         self.seq_len = seq_len\n",
    "#         self.h = h\n",
    "#         self.clip_size = clip_size\n",
    "        \n",
    "#         self.mixer_blocks1 = nn.ModuleList([\n",
    "#             self.mixer_block1(h, drop) for _ in range(n_blocks)\n",
    "#         ])\n",
    "#         self.mixer_blocks2 = nn.ModuleList([\n",
    "#             self.mixer_block2(seq_len, drop) for _ in range(n_blocks)\n",
    "#         ])\n",
    "        \n",
    "#         # Output linear layer\n",
    "#         self.backbone_linear = nn.Linear(h * seq_len, out_dim, bias=True) \n",
    "#         self.clip_proj = self.projector(clip_size, clip_size, h=clip_size)\n",
    "        \n",
    "#         if blurry_recon:\n",
    "#             self.blin1 = nn.Linear(h*seq_len,4*28*28,bias=True)\n",
    "#             self.bdropout = nn.Dropout(.3)\n",
    "#             self.bnorm = nn.GroupNorm(1, 64)\n",
    "#             self.bupsampler = Decoder(\n",
    "#                 in_channels=64,\n",
    "#                 out_channels=4,\n",
    "#                 up_block_types=[\"UpDecoderBlock2D\",\"UpDecoderBlock2D\",\"UpDecoderBlock2D\"],\n",
    "#                 block_out_channels=[32, 64, 128],\n",
    "#                 layers_per_block=1,\n",
    "#             )\n",
    "#             self.b_maps_projector = nn.Sequential(\n",
    "#                 nn.Conv2d(64, 512, 1, bias=False),\n",
    "#                 nn.GroupNorm(1,512),\n",
    "#                 nn.ReLU(True),\n",
    "#                 nn.Conv2d(512, 512, 1, bias=False),\n",
    "#                 nn.GroupNorm(1,512),\n",
    "#                 nn.ReLU(True),\n",
    "#                 nn.Conv2d(512, 512, 1, bias=True),\n",
    "#             )\n",
    "            \n",
    "#     def projector(self, in_dim, out_dim, h=2048):\n",
    "#         return nn.Sequential(\n",
    "#             nn.LayerNorm(in_dim),\n",
    "#             nn.GELU(),\n",
    "#             nn.Linear(in_dim, h),\n",
    "#             nn.LayerNorm(h),\n",
    "#             nn.GELU(),\n",
    "#             nn.Linear(h, h),\n",
    "#             nn.LayerNorm(h),\n",
    "#             nn.GELU(),\n",
    "#             nn.Linear(h, out_dim)\n",
    "#         )\n",
    "    \n",
    "#     def mlp(self, in_dim, out_dim, drop):\n",
    "#         return nn.Sequential(\n",
    "#             nn.Linear(in_dim, out_dim),\n",
    "#             nn.GELU(),\n",
    "#             nn.Dropout(drop),\n",
    "#             nn.Linear(out_dim, out_dim),\n",
    "#         )\n",
    "    \n",
    "#     def mixer_block1(self, h, drop):\n",
    "#         return nn.Sequential(\n",
    "#             nn.LayerNorm(h),\n",
    "#             self.mlp(h, h, drop),  # Token mixing\n",
    "#         )\n",
    "\n",
    "#     def mixer_block2(self, seq_len, drop):\n",
    "#         return nn.Sequential(\n",
    "#             nn.LayerNorm(seq_len),\n",
    "#             self.mlp(seq_len, seq_len, drop)  # Channel mixing\n",
    "#         )\n",
    "        \n",
    "#     def forward(self, x):\n",
    "#         # make empty tensors\n",
    "#         c,b = torch.Tensor([0.]), torch.Tensor([[0.],[0.]])\n",
    "        \n",
    "#         # Mixer blocks\n",
    "#         residual1 = x\n",
    "#         residual2 = x.permute(0,2,1)\n",
    "#         for block1, block2 in zip(self.mixer_blocks1,self.mixer_blocks2):\n",
    "#             x = block1(x) + residual1\n",
    "#             residual1 = x\n",
    "#             x = x.permute(0,2,1)\n",
    "            \n",
    "#             x = block2(x) + residual2\n",
    "#             residual2 = x\n",
    "#             x = x.permute(0,2,1)\n",
    "            \n",
    "#         x = x.reshape(x.size(0), -1)\n",
    "#         backbone = self.backbone_linear(x).reshape(len(x), -1, self.clip_size)\n",
    "#         c = self.clip_proj(backbone)\n",
    "\n",
    "#         if blurry_recon:\n",
    "#             b = self.blin1(x)\n",
    "#             b = self.bdropout(b)\n",
    "#             b = b.reshape(b.shape[0], -1, 7, 7).contiguous()\n",
    "#             b = self.bnorm(b)\n",
    "#             b_aux = self.b_maps_projector(b).flatten(2).permute(0,2,1)\n",
    "#             b_aux = b_aux.view(len(b_aux), 49, 512)\n",
    "#             b = (self.bupsampler(b), b_aux)\n",
    "        \n",
    "#         return backbone, c, b\n",
    "\n",
    "# model.backbone = BrainNetwork(h=hidden_dim, in_dim=hidden_dim, seq_len=seq_len, \n",
    "#                           clip_size=clip_emb_dim, out_dim=clip_emb_dim*clip_seq_dim)\n",
    "# utils.count_params(model.backbone)\n",
    "# utils.count_params(model)\n",
    "\n",
    "# # test that the model works on some fake data\n",
    "# b = torch.randn((2,seq_len,hidden_dim))\n",
    "# print(\"b.shape\",b.shape)\n",
    "\n",
    "# backbone_, clip_, blur_ = model.backbone(b)\n",
    "# print(backbone_.shape, clip_.shape, blur_[0].shape, blur_[1].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b397c0d7-52a3-4153-823b-c27d2eb3eeba",
   "metadata": {},
   "source": [
    "### Adding diffusion prior + unCLIP if use_prior=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "69965344-9346-4592-9cc5-e537e31d5fce",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param counts:\n",
      "259,865,216 total\n",
      "259,865,200 trainable\n",
      "param counts:\n",
      "733,360,996 total\n",
      "733,360,980 trainable\n"
     ]
    }
   ],
   "source": [
    "if use_prior:\n",
    "    from models import *\n",
    "\n",
    "    # setup diffusion prior network\n",
    "    out_dim = clip_emb_dim\n",
    "    depth = 6\n",
    "    dim_head = 52\n",
    "    heads = clip_emb_dim//52 # heads * dim_head = clip_emb_dim\n",
    "    timesteps = 100\n",
    "\n",
    "    prior_network = VersatileDiffusionPriorNetwork(\n",
    "            dim=out_dim,\n",
    "            depth=depth,\n",
    "            dim_head=dim_head,\n",
    "            heads=heads,\n",
    "            causal=False,\n",
    "            num_tokens = clip_seq_dim,\n",
    "            learned_query_mode=\"pos_emb\"\n",
    "        )\n",
    "\n",
    "    model.diffusion_prior = BrainDiffusionPrior(\n",
    "        net=prior_network,\n",
    "        image_embed_dim=out_dim,\n",
    "        condition_on_text_encodings=False,\n",
    "        timesteps=timesteps,\n",
    "        cond_drop_prob=0.2,\n",
    "        image_embed_scale=None,\n",
    "    )\n",
    "    \n",
    "    utils.count_params(model.diffusion_prior)\n",
    "    utils.count_params(model)\n",
    "    \n",
    "    # prep unCLIP\n",
    "    if visualize_prior:\n",
    "        config = OmegaConf.load(\"generative_models/configs/unclip6.yaml\")\n",
    "        config = OmegaConf.to_container(config, resolve=True)\n",
    "        unclip_params = config[\"model\"][\"params\"]\n",
    "        network_config = unclip_params[\"network_config\"]\n",
    "        denoiser_config = unclip_params[\"denoiser_config\"]\n",
    "        first_stage_config = unclip_params[\"first_stage_config\"]\n",
    "        conditioner_config = unclip_params[\"conditioner_config\"]\n",
    "        sampler_config = unclip_params[\"sampler_config\"]\n",
    "        scale_factor = unclip_params[\"scale_factor\"]\n",
    "        disable_first_stage_autocast = unclip_params[\"disable_first_stage_autocast\"]\n",
    "        offset_noise_level = unclip_params[\"loss_fn_config\"][\"params\"][\"offset_noise_level\"]\n",
    "\n",
    "        first_stage_config['target'] = 'sgm.models.autoencoder.AutoencoderKL'\n",
    "        sampler_config['params']['num_steps'] = 38\n",
    "\n",
    "        diffusion_engine = DiffusionEngine(network_config=network_config,\n",
    "                               denoiser_config=denoiser_config,\n",
    "                               first_stage_config=first_stage_config,\n",
    "                               conditioner_config=conditioner_config,\n",
    "                               sampler_config=sampler_config,\n",
    "                               scale_factor=scale_factor,\n",
    "                               disable_first_stage_autocast=disable_first_stage_autocast)\n",
    "        # set to inference\n",
    "        diffusion_engine.eval().requires_grad_(False)\n",
    "        diffusion_engine.to(device)\n",
    "\n",
    "        ckpt_path = '/weka/proj-fmri/shared/mindeyev2_dataset/unclip6_epoch0_step110000.ckpt'\n",
    "        ckpt = torch.load(ckpt_path, map_location='cpu')\n",
    "        diffusion_engine.load_state_dict(ckpt['state_dict'])\n",
    "\n",
    "        image = images[:1].to(device)\n",
    "        batch={\"jpg\": image,\n",
    "              \"original_size_as_tuple\": torch.ones(image.shape[0], 2).to(device) * 768,\n",
    "              \"crop_coords_top_left\": torch.zeros(image.shape[0], 2).to(device)}\n",
    "        out = diffusion_engine.conditioner(batch)\n",
    "        vector_suffix = out[\"vector\"].to(device)\n",
    "        print(\"vector_suffix\", vector_suffix.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec25271a-2209-400c-8026-df3b8ddc1eef",
   "metadata": {},
   "source": [
    "### Setup optimizer / lr / ckpt saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e14d0482-dc42-43b9-9ce1-953c32f2c9c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_steps 23400\n",
      "\n",
      "Done with model preparations!\n",
      "param counts:\n",
      "733,360,996 total\n",
      "733,360,980 trainable\n"
     ]
    }
   ],
   "source": [
    "no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n",
    "\n",
    "opt_grouped_parameters = [\n",
    "    # {'params': [p for n, p in model.ridge.named_parameters()], 'weight_decay': 1e-2},\n",
    "    {'params': [p for n, p in model.backbone.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': 1e-2},\n",
    "    {'params': [p for n, p in model.backbone.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0},\n",
    "]\n",
    "if use_prior:\n",
    "    opt_grouped_parameters.extend([\n",
    "        {'params': [p for n, p in model.diffusion_prior.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': 1e-2},\n",
    "        {'params': [p for n, p in model.diffusion_prior.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
    "    ])\n",
    "\n",
    "optimizer = torch.optim.AdamW(opt_grouped_parameters, lr=max_lr)\n",
    "\n",
    "if lr_scheduler_type == 'linear':\n",
    "    lr_scheduler = torch.optim.lr_scheduler.LinearLR(\n",
    "        optimizer,\n",
    "        total_iters=int(np.floor(num_epochs*num_iterations_per_epoch)),\n",
    "        last_epoch=-1\n",
    "    )\n",
    "elif lr_scheduler_type == 'cycle':\n",
    "    total_steps=int(np.floor(num_epochs*num_iterations_per_epoch))\n",
    "    print(\"total_steps\", total_steps)\n",
    "    lr_scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
    "        optimizer, \n",
    "        max_lr=max_lr,\n",
    "        total_steps=total_steps,\n",
    "        final_div_factor=1000,\n",
    "        last_epoch=-1, pct_start=2/num_epochs\n",
    "    )\n",
    "    \n",
    "def save_ckpt(tag):\n",
    "    if use_deepspeed:\n",
    "        deepspeed.DeepSpeedEngine.save_checkpoint(model, save_dir=outdir, tag=tag)\n",
    "        ckpt_path = outdir+f'/{tag}/{tag}.npy'\n",
    "        np.save(ckpt_path, {\n",
    "            'epoch': epoch,\n",
    "            'train_losses': losses,\n",
    "            'test_losses': test_losses,\n",
    "            'lrs': lrs})\n",
    "    else:\n",
    "        ckpt_path = outdir+f'/{tag}.pth'\n",
    "        unwrapped_model = accelerator.unwrap_model(model)\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': unwrapped_model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'lr_scheduler': lr_scheduler.state_dict(),\n",
    "            'train_losses': losses,\n",
    "            'test_losses': test_losses,\n",
    "            'lrs': lrs,\n",
    "            }, ckpt_path)\n",
    "        del unwrapped_model\n",
    "    print(f\"\\n---saved {outdir}/{tag} ckpt!---\\n\")\n",
    "\n",
    "def load_ckpt(tag,load_lr=True,load_optimizer=True,load_epoch=True,strict=True,outdir=outdir,use_deepspeed=use_deepspeed,multisubj_loading=False): \n",
    "    print(f\"\\n---loading {outdir}/{tag}.pth ckpt---\\n\")\n",
    "    if use_deepspeed:\n",
    "        state_dict = deepspeed.utils.zero_to_fp32.get_fp32_state_dict_from_zero_checkpoint(checkpoint_dir=outdir, tag=tag)\n",
    "        if multisubj_loading: # remove incompatible ridge layer that will otherwise error\n",
    "            state_dict.pop('ridge.linears.0.weight',None)\n",
    "        try:\n",
    "            model.module.load_state_dict(state_dict, strict=strict)\n",
    "        except:\n",
    "            model.load_state_dict(state_dict, strict=strict)\n",
    "        if load_epoch:\n",
    "            np_ckpt = np.load(outdir+f'/{tag}/{tag}.npy', allow_pickle=True).tolist()\n",
    "            globals()[\"epoch\"] = np_ckpt['epoch']\n",
    "            print(\"Epoch\",epoch)\n",
    "        if load_optimizer or load_lr:\n",
    "            print(\"cant load optimizer or lr when using deepspeed.\")\n",
    "    else:\n",
    "        checkpoint = torch.load(outdir+'/last.pth', map_location='cpu')\n",
    "        state_dict = checkpoint['model_state_dict']\n",
    "        if multisubj_loading: # remove incompatible ridge layer that will otherwise error\n",
    "            state_dict.pop('ridge.linears.0.weight',None)\n",
    "        try:\n",
    "            model.module.load_state_dict(state_dict, strict=strict)\n",
    "        except:\n",
    "            model.load_state_dict(state_dict, strict=strict)\n",
    "        if load_epoch:\n",
    "            globals()[\"epoch\"] = checkpoint['epoch']\n",
    "            print(\"Epoch\",epoch)\n",
    "        if load_optimizer:\n",
    "            optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        if load_lr:\n",
    "            lr_scheduler.load_state_dict(checkpoint['lr_scheduler'])\n",
    "        del checkpoint\n",
    "        \n",
    "print(\"\\nDone with model preparations!\")\n",
    "num_params = utils.count_params(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "983f458b-35b8-49f2-b6db-80296cece730",
   "metadata": {},
   "source": [
    "# Weights and Biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0a25a662-daa8-4de9-9233-8364800fcb6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if local_rank==0 and wandb_log: # only use main process for wandb logging\n",
    "    import wandb\n",
    "    wandb_project = 'mindeye'\n",
    "    print(f\"wandb {wandb_project} run {model_name}\")\n",
    "    # need to configure wandb beforehand in terminal with \"wandb init\"!\n",
    "    wandb_config = {\n",
    "      \"model_name\": model_name,\n",
    "      \"global_batch_size\": global_batch_size,\n",
    "      \"batch_size\": batch_size,\n",
    "      \"num_epochs\": num_epochs,\n",
    "      \"num_sessions\": num_sessions,\n",
    "      \"num_params\": num_params,\n",
    "      \"clip_scale\": clip_scale,\n",
    "      \"prior_scale\": prior_scale,\n",
    "      \"blur_scale\": blur_scale,\n",
    "      \"use_image_aug\": use_image_aug,\n",
    "      \"max_lr\": max_lr,\n",
    "      \"mixup_pct\": mixup_pct,\n",
    "      \"num_samples_per_epoch\": num_samples_per_epoch,\n",
    "      \"num_test\": num_test,\n",
    "      \"ckpt_interval\": ckpt_interval,\n",
    "      \"ckpt_saving\": ckpt_saving,\n",
    "      \"seed\": seed,\n",
    "      \"distributed\": distributed,\n",
    "      \"num_devices\": num_devices,\n",
    "      \"world_size\": world_size,\n",
    "      \"train_url\": train_url,\n",
    "      \"test_url\": test_url,\n",
    "    }\n",
    "    print(\"wandb_config:\\n\",wandb_config)\n",
    "    print(\"wandb_id:\",model_name)\n",
    "    wandb.init(\n",
    "        project=wandb_project,\n",
    "        name=model_name,\n",
    "        config=wandb_config,\n",
    "        resume=\"allow\",\n",
    "    )\n",
    "else:\n",
    "    wandb_log = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5690151-2131-4918-b750-e869cbd1a8a8",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "12de6387-6e18-4e4b-b5ce-a847d625330a",
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = 0\n",
    "losses, test_losses, lrs = [], [], []\n",
    "best_test_loss = 1e9\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "607a7c7b-fe5e-41a4-80bf-d2814b3a57cc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load multisubject stage1 ckpt if set\n",
    "if multisubject_ckpt is not None and not resume_from_ckpt:\n",
    "    # if multisubject_ckpt was saved using deepspeed but currently you are not, you'll need to import deepspeed and manually set use_deepspeed to True in the load_ckpt function\n",
    "    # import deepspeed\n",
    "    load_ckpt(\"last\",outdir=multisubject_ckpt,load_lr=False,load_optimizer=False,load_epoch=False,strict=False,use_deepspeed=use_deepspeed,multisubj_loading=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5453c316-0cb0-4bee-8585-f44dff746e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load saved ckpt model weights into current model\n",
    "if resume_from_ckpt:\n",
    "    load_ckpt(\"last\",load_lr=True,load_optimizer=True,load_epoch=True)\n",
    "elif wandb_log:\n",
    "    if wandb.run.resumed:\n",
    "        load_ckpt(\"last\",load_lr=True,load_optimizer=True,load_epoch=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "99f09f76-4481-4133-b09a-a22b10dbc0c4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[93m [WARNING] \u001b[0m DeepSpeed Op Builder: Installed CUDA version 12.1 does not match the version torch was compiled with 11.7.Detected `DS_SKIP_CUDA_CHECK=1`: Allowing this combination of CUDA, but it may result in unexpected behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using /admin/home-conscioustahoe/.cache/torch_extensions/py311_cu117 as PyTorch extensions root...\n",
      "Detected CUDA files, patching ldflags\n",
      "Emitting ninja build file /admin/home-conscioustahoe/.cache/torch_extensions/py311_cu117/cpu_adam/build.ninja...\n",
      "Building extension module cpu_adam...\n",
      "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ninja: no work to do.\n",
      "Time to load cpu_adam op: 2.811321496963501 seconds\n",
      "[2024-01-22 20:53:47,011] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed info: version=0.12.6, git-hash=unknown, git-branch=unknown\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading extension module cpu_adam...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-01-22 20:53:47,922] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False\n",
      "[2024-01-22 20:53:47,924] [INFO] [logging.py:96:log_dist] [Rank 0] Using client Optimizer as basic optimizer\n",
      "[2024-01-22 20:53:47,924] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the basic Optimizer\n",
      "[2024-01-22 20:53:47,928] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = DeepSpeedCPUAdam\n",
      "[2024-01-22 20:53:47,928] [INFO] [utils.py:56:is_zero_supported_optimizer] Checking ZeRO support for optimizer=DeepSpeedCPUAdam type=<class 'deepspeed.ops.adam.cpu_adam.DeepSpeedCPUAdam'>\n",
      "[2024-01-22 20:53:47,928] [INFO] [logging.py:96:log_dist] [Rank 0] Creating torch.float16 ZeRO stage 2 optimizer\n",
      "[2024-01-22 20:53:47,929] [INFO] [stage_1_and_2.py:148:__init__] Reduce bucket size 10000000\n",
      "[2024-01-22 20:53:47,929] [INFO] [stage_1_and_2.py:149:__init__] Allgather bucket size 500,000,000\n",
      "[2024-01-22 20:53:47,929] [INFO] [stage_1_and_2.py:150:__init__] CPU Offload: True\n",
      "[2024-01-22 20:53:47,929] [INFO] [stage_1_and_2.py:151:__init__] Round robin gradient partitioning: False\n",
      "[2024-01-22 20:53:51,867] [INFO] [utils.py:791:see_memory_usage] Before initializing optimizer states\n",
      "[2024-01-22 20:53:51,868] [INFO] [utils.py:792:see_memory_usage] MA 10.92 GB         Max_MA 10.92 GB         CA 11.04 GB         Max_CA 11 GB \n",
      "[2024-01-22 20:53:51,868] [INFO] [utils.py:799:see_memory_usage] CPU Virtual Memory:  used = 354.63 GB, percent = 31.6%\n",
      "[2024-01-22 20:53:54,661] [INFO] [utils.py:791:see_memory_usage] After initializing optimizer states\n",
      "[2024-01-22 20:53:54,662] [INFO] [utils.py:792:see_memory_usage] MA 10.92 GB         Max_MA 10.92 GB         CA 11.04 GB         Max_CA 11 GB \n",
      "[2024-01-22 20:53:54,663] [INFO] [utils.py:799:see_memory_usage] CPU Virtual Memory:  used = 363.18 GB, percent = 32.4%\n",
      "[2024-01-22 20:53:54,663] [INFO] [stage_1_and_2.py:516:__init__] optimizer state initialized\n",
      "[2024-01-22 20:53:54,849] [INFO] [utils.py:791:see_memory_usage] After initializing ZeRO optimizer\n",
      "[2024-01-22 20:53:54,850] [INFO] [utils.py:792:see_memory_usage] MA 10.92 GB         Max_MA 10.92 GB         CA 11.04 GB         Max_CA 11 GB \n",
      "[2024-01-22 20:53:54,850] [INFO] [utils.py:799:see_memory_usage] CPU Virtual Memory:  used = 363.18 GB, percent = 32.4%\n",
      "[2024-01-22 20:53:54,857] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Final Optimizer = DeepSpeedCPUAdam\n",
      "[2024-01-22 20:53:54,857] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed using client LR scheduler\n",
      "[2024-01-22 20:53:54,857] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed LR Scheduler = None\n",
      "[2024-01-22 20:53:54,858] [INFO] [logging.py:96:log_dist] [Rank 0] step=0, skipped=0, lr=[1.200000000000002e-05, 1.200000000000002e-05, 1.200000000000002e-05, 1.200000000000002e-05], mom=[(0.95, 0.999), (0.95, 0.999), (0.95, 0.999), (0.95, 0.999)]\n",
      "[2024-01-22 20:53:54,858] [INFO] [config.py:984:print] DeepSpeedEngine configuration:\n",
      "[2024-01-22 20:53:54,859] [INFO] [config.py:988:print]   activation_checkpointing_config  {\n",
      "    \"partition_activations\": false, \n",
      "    \"contiguous_memory_optimization\": false, \n",
      "    \"cpu_checkpointing\": false, \n",
      "    \"number_checkpoints\": null, \n",
      "    \"synchronize_checkpoint_boundary\": false, \n",
      "    \"profile\": false\n",
      "}\n",
      "[2024-01-22 20:53:54,859] [INFO] [config.py:988:print]   aio_config ................... {'block_size': 26214400, 'queue_depth': 32, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}\n",
      "[2024-01-22 20:53:54,859] [INFO] [config.py:988:print]   amp_enabled .................. False\n",
      "[2024-01-22 20:53:54,860] [INFO] [config.py:988:print]   amp_params ................... False\n",
      "[2024-01-22 20:53:54,860] [INFO] [config.py:988:print]   autotuning_config ............ {\n",
      "    \"enabled\": false, \n",
      "    \"start_step\": null, \n",
      "    \"end_step\": null, \n",
      "    \"metric_path\": null, \n",
      "    \"arg_mappings\": null, \n",
      "    \"metric\": \"throughput\", \n",
      "    \"model_info\": null, \n",
      "    \"results_dir\": \"autotuning_results\", \n",
      "    \"exps_dir\": \"autotuning_exps\", \n",
      "    \"overwrite\": true, \n",
      "    \"fast\": true, \n",
      "    \"start_profile_step\": 3, \n",
      "    \"end_profile_step\": 5, \n",
      "    \"tuner_type\": \"gridsearch\", \n",
      "    \"tuner_early_stopping\": 5, \n",
      "    \"tuner_num_trials\": 50, \n",
      "    \"model_info_path\": null, \n",
      "    \"mp_size\": 1, \n",
      "    \"max_train_batch_size\": null, \n",
      "    \"min_train_batch_size\": 1, \n",
      "    \"max_train_micro_batch_size_per_gpu\": 1.024000e+03, \n",
      "    \"min_train_micro_batch_size_per_gpu\": 1, \n",
      "    \"num_tuning_micro_batch_sizes\": 3\n",
      "}\n",
      "[2024-01-22 20:53:54,860] [INFO] [config.py:988:print]   bfloat16_enabled ............. False\n",
      "[2024-01-22 20:53:54,861] [INFO] [config.py:988:print]   checkpoint_parallel_write_pipeline  False\n",
      "[2024-01-22 20:53:54,861] [INFO] [config.py:988:print]   checkpoint_tag_validation_enabled  True\n",
      "[2024-01-22 20:53:54,861] [INFO] [config.py:988:print]   checkpoint_tag_validation_fail  False\n",
      "[2024-01-22 20:53:54,861] [INFO] [config.py:988:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f9a70220310>\n",
      "[2024-01-22 20:53:54,862] [INFO] [config.py:988:print]   communication_data_type ...... None\n",
      "[2024-01-22 20:53:54,862] [INFO] [config.py:988:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}\n",
      "[2024-01-22 20:53:54,862] [INFO] [config.py:988:print]   curriculum_enabled_legacy .... False\n",
      "[2024-01-22 20:53:54,862] [INFO] [config.py:988:print]   curriculum_params_legacy ..... False\n",
      "[2024-01-22 20:53:54,862] [INFO] [config.py:988:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}\n",
      "[2024-01-22 20:53:54,863] [INFO] [config.py:988:print]   data_efficiency_enabled ...... False\n",
      "[2024-01-22 20:53:54,863] [INFO] [config.py:988:print]   dataloader_drop_last ......... False\n",
      "[2024-01-22 20:53:54,863] [INFO] [config.py:988:print]   disable_allgather ............ False\n",
      "[2024-01-22 20:53:54,863] [INFO] [config.py:988:print]   dump_state ................... False\n",
      "[2024-01-22 20:53:54,864] [INFO] [config.py:988:print]   dynamic_loss_scale_args ...... None\n",
      "[2024-01-22 20:53:54,864] [INFO] [config.py:988:print]   eigenvalue_enabled ........... False\n",
      "[2024-01-22 20:53:54,864] [INFO] [config.py:988:print]   eigenvalue_gas_boundary_resolution  1\n",
      "[2024-01-22 20:53:54,864] [INFO] [config.py:988:print]   eigenvalue_layer_name ........ bert.encoder.layer\n",
      "[2024-01-22 20:53:54,864] [INFO] [config.py:988:print]   eigenvalue_layer_num ......... 0\n",
      "[2024-01-22 20:53:54,865] [INFO] [config.py:988:print]   eigenvalue_max_iter .......... 100\n",
      "[2024-01-22 20:53:54,865] [INFO] [config.py:988:print]   eigenvalue_stability ......... 1e-06\n",
      "[2024-01-22 20:53:54,865] [INFO] [config.py:988:print]   eigenvalue_tol ............... 0.01\n",
      "[2024-01-22 20:53:54,865] [INFO] [config.py:988:print]   eigenvalue_verbose ........... False\n",
      "[2024-01-22 20:53:54,866] [INFO] [config.py:988:print]   elasticity_enabled ........... False\n",
      "[2024-01-22 20:53:54,866] [INFO] [config.py:988:print]   flops_profiler_config ........ {\n",
      "    \"enabled\": false, \n",
      "    \"recompute_fwd_factor\": 0.0, \n",
      "    \"profile_step\": 1, \n",
      "    \"module_depth\": -1, \n",
      "    \"top_modules\": 1, \n",
      "    \"detailed\": true, \n",
      "    \"output_file\": null\n",
      "}\n",
      "[2024-01-22 20:53:54,866] [INFO] [config.py:988:print]   fp16_auto_cast ............... False\n",
      "[2024-01-22 20:53:54,866] [INFO] [config.py:988:print]   fp16_enabled ................. True\n",
      "[2024-01-22 20:53:54,866] [INFO] [config.py:988:print]   fp16_master_weights_and_gradients  False\n",
      "[2024-01-22 20:53:54,867] [INFO] [config.py:988:print]   global_rank .................. 0\n",
      "[2024-01-22 20:53:54,867] [INFO] [config.py:988:print]   grad_accum_dtype ............. None\n",
      "[2024-01-22 20:53:54,867] [INFO] [config.py:988:print]   gradient_accumulation_steps .. 1\n",
      "[2024-01-22 20:53:54,867] [INFO] [config.py:988:print]   gradient_clipping ............ 1.0\n",
      "[2024-01-22 20:53:54,868] [INFO] [config.py:988:print]   gradient_predivide_factor .... 1.0\n",
      "[2024-01-22 20:53:54,868] [INFO] [config.py:988:print]   graph_harvesting ............. False\n",
      "[2024-01-22 20:53:54,868] [INFO] [config.py:988:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8\n",
      "[2024-01-22 20:53:54,868] [INFO] [config.py:988:print]   initial_dynamic_scale ........ 65536\n",
      "[2024-01-22 20:53:54,869] [INFO] [config.py:988:print]   load_universal_checkpoint .... False\n",
      "[2024-01-22 20:53:54,869] [INFO] [config.py:988:print]   loss_scale ................... 0\n",
      "[2024-01-22 20:53:54,869] [INFO] [config.py:988:print]   memory_breakdown ............. False\n",
      "[2024-01-22 20:53:54,869] [INFO] [config.py:988:print]   mics_hierarchial_params_gather  False\n",
      "[2024-01-22 20:53:54,869] [INFO] [config.py:988:print]   mics_shard_size .............. -1\n",
      "[2024-01-22 20:53:54,870] [INFO] [config.py:988:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False\n",
      "[2024-01-22 20:53:54,870] [INFO] [config.py:988:print]   nebula_config ................ {\n",
      "    \"enabled\": false, \n",
      "    \"persistent_storage_path\": null, \n",
      "    \"persistent_time_interval\": 100, \n",
      "    \"num_of_version_in_retention\": 2, \n",
      "    \"enable_nebula_load\": true, \n",
      "    \"load_path\": null\n",
      "}\n",
      "[2024-01-22 20:53:54,870] [INFO] [config.py:988:print]   optimizer_legacy_fusion ...... False\n",
      "[2024-01-22 20:53:54,871] [INFO] [config.py:988:print]   optimizer_name ............... None\n",
      "[2024-01-22 20:53:54,871] [INFO] [config.py:988:print]   optimizer_params ............. None\n",
      "[2024-01-22 20:53:54,871] [INFO] [config.py:988:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0, 'pipe_partitioned': True, 'grad_partitioned': True}\n",
      "[2024-01-22 20:53:54,871] [INFO] [config.py:988:print]   pld_enabled .................. False\n",
      "[2024-01-22 20:53:54,872] [INFO] [config.py:988:print]   pld_params ................... False\n",
      "[2024-01-22 20:53:54,872] [INFO] [config.py:988:print]   prescale_gradients ........... False\n",
      "[2024-01-22 20:53:54,872] [INFO] [config.py:988:print]   scheduler_name ............... None\n",
      "[2024-01-22 20:53:54,872] [INFO] [config.py:988:print]   scheduler_params ............. None\n",
      "[2024-01-22 20:53:54,872] [INFO] [config.py:988:print]   seq_parallel_communication_data_type  torch.float32\n",
      "[2024-01-22 20:53:54,873] [INFO] [config.py:988:print]   sparse_attention ............. None\n",
      "[2024-01-22 20:53:54,873] [INFO] [config.py:988:print]   sparse_gradients_enabled ..... False\n",
      "[2024-01-22 20:53:54,873] [INFO] [config.py:988:print]   steps_per_print .............. inf\n",
      "[2024-01-22 20:53:54,873] [INFO] [config.py:988:print]   train_batch_size ............. 16\n",
      "[2024-01-22 20:53:54,874] [INFO] [config.py:988:print]   train_micro_batch_size_per_gpu  16\n",
      "[2024-01-22 20:53:54,874] [INFO] [config.py:988:print]   use_data_before_expert_parallel_  False\n",
      "[2024-01-22 20:53:54,874] [INFO] [config.py:988:print]   use_node_local_storage ....... False\n",
      "[2024-01-22 20:53:54,874] [INFO] [config.py:988:print]   wall_clock_breakdown ......... False\n",
      "[2024-01-22 20:53:54,874] [INFO] [config.py:988:print]   weight_quantization_config ... None\n",
      "[2024-01-22 20:53:54,875] [INFO] [config.py:988:print]   world_size ................... 1\n",
      "[2024-01-22 20:53:54,875] [INFO] [config.py:988:print]   zero_allow_untested_optimizer  True\n",
      "[2024-01-22 20:53:54,875] [INFO] [config.py:988:print]   zero_config .................. stage=2 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=10000000 use_multi_rank_bucket_allreduce=True allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=DeepSpeedZeroOffloadParamConfig(device='none', nvme_path=PosixPath('/scratch'), buffer_count=5, buffer_size=4000000000, max_in_cpu=1,000,000,000, pin_memory=True) offload_optimizer=DeepSpeedZeroOffloadOptimizerConfig(device='cpu', nvme_path=PosixPath('/scratch'), buffer_count=4, pin_memory=True, pipeline=False, pipeline_read=False, pipeline_write=False, fast_init=False, ratio=1.0) sub_group_size=1000000000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=10000000 param_persistence_threshold=100000 model_persistence_threshold=sys.maxsize max_live_parameters=1000000000 max_reuse_distance=1000000000 gather_16bit_weights_on_model_save=True stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True pipeline_loading_checkpoint=False override_module_apply=True\n",
      "[2024-01-22 20:53:54,876] [INFO] [config.py:988:print]   zero_enabled ................. True\n",
      "[2024-01-22 20:53:54,876] [INFO] [config.py:988:print]   zero_force_ds_cpu_optimizer .. True\n",
      "[2024-01-22 20:53:54,876] [INFO] [config.py:988:print]   zero_optimization_stage ...... 2\n",
      "[2024-01-22 20:53:54,876] [INFO] [config.py:974:print_user_config]   json = {\n",
      "    \"bf16\": {\n",
      "        \"enabled\": false\n",
      "    }, \n",
      "    \"fp16\": {\n",
      "        \"enabled\": true\n",
      "    }, \n",
      "    \"zero_optimization\": {\n",
      "        \"stage\": 2, \n",
      "        \"contiguous_gradients\": true, \n",
      "        \"stage3_gather_16bit_weights_on_model_save\": true, \n",
      "        \"stage3_max_live_parameters\": 1.000000e+09, \n",
      "        \"stage3_max_reuse_distance\": 1.000000e+09, \n",
      "        \"stage3_prefetch_bucket_size\": 1.000000e+07, \n",
      "        \"stage3_param_persistence_threshold\": 1.000000e+05, \n",
      "        \"reduce_bucket_size\": 1.000000e+07, \n",
      "        \"sub_group_size\": 1.000000e+09, \n",
      "        \"offload_optimizer\": {\n",
      "            \"device\": \"cpu\", \n",
      "            \"nvme_path\": \"/scratch\", \n",
      "            \"pin_memory\": true\n",
      "        }, \n",
      "        \"offload_param\": {\n",
      "            \"device\": \"none\", \n",
      "            \"nvme_path\": \"/scratch\", \n",
      "            \"buffer_size\": 4.000000e+09, \n",
      "            \"pin_memory\": true\n",
      "        }\n",
      "    }, \n",
      "    \"aio\": {\n",
      "        \"block_size\": 2.621440e+07, \n",
      "        \"queue_depth\": 32, \n",
      "        \"thread_count\": 1, \n",
      "        \"single_submit\": false, \n",
      "        \"overlap_events\": true\n",
      "    }, \n",
      "    \"gradient_accumulation_steps\": 1, \n",
      "    \"gradient_clipping\": 1.0, \n",
      "    \"steps_per_print\": inf, \n",
      "    \"train_batch_size\": 16, \n",
      "    \"train_micro_batch_size_per_gpu\": 16, \n",
      "    \"wall_clock_breakdown\": false, \n",
      "    \"zero_allow_untested_optimizer\": true\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "train_dls = [train_dl[f'subj0{s}'] for s in subj_list]\n",
    "\n",
    "model, optimizer, *train_dls, lr_scheduler = accelerator.prepare(model, optimizer, *train_dls, lr_scheduler)\n",
    "# leaving out test_dl since we will only have local_rank 0 device do evals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "60be0d5f-3e94-4612-9373-61b53d836393",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing starting with epoch 0 / 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adam Optimizer #0 is created with AVX512 arithmetic capability.\n",
      "Config: alpha=0.000300, betas=(0.900000, 0.999000), weight_decay=0.010000, adam_w=1\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/admin/home-conscioustahoe/miniconda3/envs/fmri2/lib/python3.11/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-01-22 20:54:09,100] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 4294967296, reducing to 2147483648\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "[2024-01-22 20:54:10,025] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 2147483648, reducing to 1073741824\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "[2024-01-22 20:54:10,946] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 1073741824, reducing to 536870912\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "[2024-01-22 20:54:11,870] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 536870912, reducing to 268435456\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "[2024-01-22 20:54:12,792] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 268435456, reducing to 134217728\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "[2024-01-22 20:54:13,716] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 134217728, reducing to 67108864\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "[2024-01-22 20:54:14,639] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 67108864, reducing to 33554432\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "[2024-01-22 20:54:15,560] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 33554432, reducing to 16777216\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "[2024-01-22 20:54:16,486] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 16777216, reducing to 8388608\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "[2024-01-22 20:54:17,414] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 8388608, reducing to 4194304\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "[2024-01-22 20:54:18,340] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 4194304, reducing to 2097152\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "[2024-01-22 20:54:19,267] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 2097152, reducing to 1048576\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "[2024-01-22 20:54:20,192] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 1048576, reducing to 524288\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "[2024-01-22 20:54:21,114] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 524288, reducing to 262144\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "[2024-01-22 20:54:22,040] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 262144, reducing to 131072\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "[2024-01-22 20:54:22,965] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 131072, reducing to 65536\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "[2024-01-22 20:54:23,891] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 65536, reducing to 32768\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "[2024-01-22 20:54:24,815] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 32768, reducing to 16384\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "[2024-01-22 20:54:25,741] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 16384, reducing to 8192\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "[2024-01-22 20:54:26,666] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 8192, reducing to 4096\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "---\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x400 with 8 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        | 0/50 [15:04<?, ?it/s, test/blurry_pixcorr=0.167, test/loss=21.2, test/loss_clip_total=3.52, test/loss_prior=0.588, test/num_steps=1, test/recon_cossim=0, test/recon_mse=0, test/test_bwd_pct_correct=0.103, test/test_fwd_pct_correct=0.203, train/blurry_pixcorr=0.154, train/bwd_pct_correct=0.267, train/fwd_pct_correct=0.321, train/loss=28, train/loss_blurry_cont_total=6.61, train/loss_blurry_total=0.621, train/loss_clip_total=1.98, train/loss_prior=0.845, train/lr=0.000146, train/num_steps=468, train/recon_cossim=0.323, train/recon_mse=0.845]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-01-22 21:08:59,864] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint last is about to be saved!\n",
      "[2024-01-22 21:08:59,905] [INFO] [logging.py:96:log_dist] [Rank 0] Saving model checkpoint: /weka/proj-fmri/conscioustahoe/MindEyeV2/train_logs/testing/last/mp_rank_00_model_states.pt\n",
      "[2024-01-22 21:08:59,905] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /weka/proj-fmri/conscioustahoe/MindEyeV2/train_logs/testing/last/mp_rank_00_model_states.pt...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/admin/home-conscioustahoe/miniconda3/envs/fmri2/lib/python3.11/site-packages/torch/nn/modules/module.py:1802: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-01-22 21:09:02,790] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /weka/proj-fmri/conscioustahoe/MindEyeV2/train_logs/testing/last/mp_rank_00_model_states.pt.\n",
      "[2024-01-22 21:09:02,800] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /weka/proj-fmri/conscioustahoe/MindEyeV2/train_logs/testing/last/zero_pp_rank_0_mp_rank_00_optim_states.pt...\n",
      "[2024-01-22 21:09:13,596] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /weka/proj-fmri/conscioustahoe/MindEyeV2/train_logs/testing/last/zero_pp_rank_0_mp_rank_00_optim_states.pt.\n",
      "[2024-01-22 21:09:14,948] [INFO] [engine.py:3431:_save_zero_checkpoint] zero checkpoint saved /weka/proj-fmri/conscioustahoe/MindEyeV2/train_logs/testing/last/zero_pp_rank_0_mp_rank_00_optim_states.pt\n",
      "[2024-01-22 21:09:14,948] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint last is ready now!\n",
      "\n",
      "---saved /weka/proj-fmri/conscioustahoe/MindEyeV2/train_logs/testing/last ckpt!---\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               | 1/50 [15:20<12:32:02, 920.88s/it, test/blurry_pixcorr=0.167, test/loss=21.2, test/loss_clip_total=3.52, test/loss_prior=0.588, test/num_steps=1, test/recon_cossim=0, test/recon_mse=0, test/test_bwd_pct_correct=0.103, test/test_fwd_pct_correct=0.203, train/blurry_pixcorr=0.154, train/bwd_pct_correct=0.267, train/fwd_pct_correct=0.321, train/loss=28, train/loss_blurry_cont_total=6.61, train/loss_blurry_total=0.621, train/loss_clip_total=1.98, train/loss_prior=0.845, train/lr=0.000146, train/num_steps=468, train/recon_cossim=0.323, train/recon_mse=0.845]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n",
      "length of voxel_list: 1\n",
      "first element of voxel_list: torch.Size([16, 1, 15724])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              | 1/50 [18:46<15:19:56, 1126.46s/it, test/blurry_pixcorr=0.167, test/loss=21.2, test/loss_clip_total=3.52, test/loss_prior=0.588, test/num_steps=1, test/recon_cossim=0, test/recon_mse=0, test/test_bwd_pct_correct=0.103, test/test_fwd_pct_correct=0.203, train/blurry_pixcorr=0.154, train/bwd_pct_correct=0.267, train/fwd_pct_correct=0.321, train/loss=28, train/loss_blurry_cont_total=6.61, train/loss_blurry_total=0.621, train/loss_clip_total=1.98, train/loss_prior=0.845, train/lr=0.000146, train/num_steps=468, train/recon_cossim=0.323, train/recon_mse=0.845]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 196\u001b[0m\n\u001b[1;32m    193\u001b[0m         blurry_pixcorr \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m pixcorr\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m    195\u001b[0m utils\u001b[38;5;241m.\u001b[39mcheck_loss(loss)\n\u001b[0;32m--> 196\u001b[0m \u001b[43maccelerator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    197\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m    199\u001b[0m losses\u001b[38;5;241m.\u001b[39mappend(loss\u001b[38;5;241m.\u001b[39mitem())\n",
      "File \u001b[0;32m~/miniconda3/envs/fmri2/lib/python3.11/site-packages/accelerate/accelerator.py:1958\u001b[0m, in \u001b[0;36mAccelerator.backward\u001b[0;34m(self, loss, **kwargs)\u001b[0m\n\u001b[1;32m   1956\u001b[0m     loss \u001b[38;5;241m=\u001b[39m loss \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgradient_accumulation_steps\n\u001b[1;32m   1957\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdistributed_type \u001b[38;5;241m==\u001b[39m DistributedType\u001b[38;5;241m.\u001b[39mDEEPSPEED:\n\u001b[0;32m-> 1958\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdeepspeed_engine_wrapped\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1959\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdistributed_type \u001b[38;5;241m==\u001b[39m DistributedType\u001b[38;5;241m.\u001b[39mMEGATRON_LM:\n\u001b[1;32m   1960\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/fmri2/lib/python3.11/site-packages/accelerate/utils/deepspeed.py:167\u001b[0m, in \u001b[0;36mDeepSpeedEngineWrapper.backward\u001b[0;34m(self, loss, **kwargs)\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbackward\u001b[39m(\u001b[38;5;28mself\u001b[39m, loss, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    166\u001b[0m     \u001b[38;5;66;03m# runs backpropagation and handles mixed precision\u001b[39;00m\n\u001b[0;32m--> 167\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    169\u001b[0m     \u001b[38;5;66;03m# Deepspeed's `engine.step` performs the following operations:\u001b[39;00m\n\u001b[1;32m    170\u001b[0m     \u001b[38;5;66;03m# - gradient accumulation check\u001b[39;00m\n\u001b[1;32m    171\u001b[0m     \u001b[38;5;66;03m# - gradient clipping\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    174\u001b[0m     \u001b[38;5;66;03m# - checking overflow\u001b[39;00m\n\u001b[1;32m    175\u001b[0m     \u001b[38;5;66;03m# - lr_scheduler step (only if engine.lr_scheduler is not None)\u001b[39;00m\n\u001b[1;32m    176\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[0;32m~/miniconda3/envs/fmri2/lib/python3.11/site-packages/deepspeed/utils/nvtx.py:15\u001b[0m, in \u001b[0;36minstrument_w_nvtx.<locals>.wrapped_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped_fn\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     14\u001b[0m     get_accelerator()\u001b[38;5;241m.\u001b[39mrange_push(func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m)\n\u001b[0;32m---> 15\u001b[0m     ret_val \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m     get_accelerator()\u001b[38;5;241m.\u001b[39mrange_pop()\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ret_val\n",
      "File \u001b[0;32m~/miniconda3/envs/fmri2/lib/python3.11/site-packages/deepspeed/runtime/engine.py:1955\u001b[0m, in \u001b[0;36mDeepSpeedEngine.backward\u001b[0;34m(self, loss, allreduce_gradients, release_loss, retain_graph, scale_wrt_gas)\u001b[0m\n\u001b[1;32m   1953\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mzero_optimization():\n\u001b[1;32m   1954\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mis_gradient_accumulation_boundary \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_gradient_accumulation_boundary()\n\u001b[0;32m-> 1955\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretain_graph\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1956\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mamp_enabled():\n\u001b[1;32m   1957\u001b[0m     \u001b[38;5;66;03m# AMP requires delaying unscale when inside gradient accumulation boundaries\u001b[39;00m\n\u001b[1;32m   1958\u001b[0m     \u001b[38;5;66;03m# https://nvidia.github.io/apex/advanced.html#gradient-accumulation-across-iterations\u001b[39;00m\n\u001b[1;32m   1959\u001b[0m     delay_unscale \u001b[38;5;241m=\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_gradient_accumulation_boundary()\n",
      "File \u001b[0;32m~/miniconda3/envs/fmri2/lib/python3.11/site-packages/deepspeed/runtime/zero/stage_1_and_2.py:2019\u001b[0m, in \u001b[0;36mDeepSpeedZeroOptimizer.backward\u001b[0;34m(self, loss, retain_graph)\u001b[0m\n\u001b[1;32m   2017\u001b[0m     scaled_loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m   2018\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2019\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloss_scaler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretain_graph\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2021\u001b[0m \u001b[38;5;66;03m# Only for Stage 1, Mode 2\u001b[39;00m\n\u001b[1;32m   2022\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_grad_accum_attribute:\n",
      "File \u001b[0;32m~/miniconda3/envs/fmri2/lib/python3.11/site-packages/deepspeed/runtime/fp16/loss_scaler.py:63\u001b[0m, in \u001b[0;36mLossScalerBase.backward\u001b[0;34m(self, loss, retain_graph)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbackward\u001b[39m(\u001b[38;5;28mself\u001b[39m, loss, retain_graph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m     62\u001b[0m     scaled_loss \u001b[38;5;241m=\u001b[39m loss \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss_scale\n\u001b[0;32m---> 63\u001b[0m     \u001b[43mscaled_loss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretain_graph\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/fmri2/lib/python3.11/site-packages/torch/_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    478\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    479\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    480\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    485\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    486\u001b[0m     )\n\u001b[0;32m--> 487\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    488\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    489\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/fmri2/lib/python3.11/site-packages/torch/autograd/__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    195\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    197\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 200\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    201\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    202\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(f\"{model_name} starting with epoch {epoch} / {num_epochs}\")\n",
    "progress_bar = tqdm(range(epoch,num_epochs), ncols=1200, disable=(local_rank!=0))\n",
    "test_image, test_voxel = None, None\n",
    "mse = nn.MSELoss()\n",
    "l1 = nn.L1Loss()\n",
    "soft_loss_temps = utils.cosine_anneal(0.004, 0.0075, num_epochs - int(mixup_pct * num_epochs))\n",
    "\n",
    "for epoch in progress_bar:\n",
    "    model.train()\n",
    "\n",
    "    fwd_percent_correct = 0.\n",
    "    bwd_percent_correct = 0.\n",
    "    test_fwd_percent_correct = 0.\n",
    "    test_bwd_percent_correct = 0.\n",
    "    \n",
    "    recon_cossim = 0.\n",
    "    test_recon_cossim = 0.\n",
    "    recon_mse = 0.\n",
    "    test_recon_mse = 0.\n",
    "\n",
    "    loss_clip_total = 0.\n",
    "    loss_blurry_total = 0.\n",
    "    loss_blurry_cont_total = 0.\n",
    "    test_loss_clip_total = 0.\n",
    "    \n",
    "    loss_prior_total = 0.\n",
    "    test_loss_prior_total = 0.\n",
    "\n",
    "    blurry_pixcorr = 0.\n",
    "    test_blurry_pixcorr = 0. # needs >.456 to beat low-level subj01 results in mindeye v1\n",
    "\n",
    "    # pre-load all batches for this epoch (it's MUCH faster to pre-load in bulk than to separate loading per batch)\n",
    "    voxel_iters = {} # empty dict because diff subjects have differing # of voxels\n",
    "    image_iters = torch.zeros(num_iterations_per_epoch, batch_size*len(subj_list), 3, 224, 224).float()\n",
    "    annot_iters = {}\n",
    "    perm_iters, betas_iters, select_iters = {}, {}, {}\n",
    "    for s, train_dl in enumerate(train_dls):\n",
    "        with torch.cuda.amp.autocast(dtype=data_type):\n",
    "            for iter, (behav0, past_behav0, future_behav0, old_behav0) in enumerate(train_dl):    \n",
    "                image0 = images[behav0[:,0,0].cpu().long()].float()\n",
    "                image_iters[iter,s*batch_size:s*batch_size+batch_size] = image0\n",
    "                \n",
    "                voxel0 = voxels[f'subj0{subj_list[s]}'][behav0[:,0,5].cpu().long()]\n",
    "                voxel0 = torch.Tensor(voxel0)\n",
    "                \n",
    "                if seq_len==1:\n",
    "                    voxel0 = voxel0.unsqueeze(1)\n",
    "                else:\n",
    "                    if seq_past>0:\n",
    "                        past_behavior = past_behav0[:,:(seq_past),5].cpu().long()\n",
    "                        past_voxel0 = voxels[f'subj0{subj_list[s]}'][past_behavior]\n",
    "                        past_voxel0[past_behavior==-1] = voxel0[torch.where(past_behavior==-1)[0]] # replace invalid past voxels \n",
    "                        past_voxel0 = torch.Tensor(past_voxel0)\n",
    "\n",
    "                        # if shared1000, then you need to mask it out \n",
    "                        for p in range(seq_past):\n",
    "                            mask = (past_behav0[:,p,-1] == 1) # [16,] bool\n",
    "                            index = torch.nonzero(mask.cpu()).squeeze()\n",
    "                            past_voxel0[index,p,:] = torch.zeros_like(past_voxel0[index,p,:])\n",
    "\n",
    "                    if seq_future>0:\n",
    "                        future_behavior = future_behav0[:,:(seq_future),5].cpu().long()\n",
    "                        future_voxel0 = voxels[f'subj0{subj_list[s]}'][future_behavior]\n",
    "                        future_voxel0[future_behavior==-1] = voxel0[torch.where(future_behavior==-1)[0]] # replace invalid past voxels \n",
    "                        future_voxel0 = torch.Tensor(future_voxel0)\n",
    "\n",
    "                        # if shared1000, then you need to mask it out \n",
    "                        for p in range(seq_future):\n",
    "                            mask = (future_behav0[:,p,-1] == 1) # [16,] bool\n",
    "                            index = torch.nonzero(mask.cpu()).squeeze()\n",
    "                            future_voxel0[index,p,:] = torch.zeros_like(future_voxel0[index,p,:])\n",
    "\n",
    "                    # concatenate current timepoint with past/future\n",
    "                    if seq_past > 0 and seq_future > 0:\n",
    "                        voxel0 = torch.cat((voxel0.unsqueeze(1), past_voxel0), axis=1)\n",
    "                        voxel0 = torch.cat((voxel0, future_voxel0), axis=1)\n",
    "                    elif seq_past > 0:\n",
    "                        voxel0 = torch.cat((voxel0.unsqueeze(1), past_voxel0), axis=1)\n",
    "                    else:\n",
    "                        voxel0 = torch.cat((voxel0.unsqueeze(1), future_voxel0), axis=1)\n",
    "\n",
    "                if epoch < int(mixup_pct * num_epochs):\n",
    "                    voxel0, perm, betas, select = utils.mixco(voxel0)\n",
    "                    perm_iters[f\"subj0{subj_list[s]}_iter{iter}\"] = perm\n",
    "                    betas_iters[f\"subj0{subj_list[s]}_iter{iter}\"] = betas\n",
    "                    select_iters[f\"subj0{subj_list[s]}_iter{iter}\"] = select\n",
    "\n",
    "                voxel_iters[f\"subj0{subj_list[s]}_iter{iter}\"] = voxel0\n",
    "\n",
    "                if iter >= num_iterations_per_epoch-1:\n",
    "                    break\n",
    "\n",
    "    # you now have voxel_iters and image_iters with num_iterations_per_epoch batches each\n",
    "    for train_i in range(num_iterations_per_epoch):\n",
    "        with torch.cuda.amp.autocast(dtype=data_type):\n",
    "            optimizer.zero_grad()\n",
    "            loss=0.\n",
    "\n",
    "            voxel_list = [voxel_iters[f\"subj0{s}_iter{train_i}\"].detach().to(device) for s in subj_list]\n",
    "            image = image_iters[train_i].detach()\n",
    "            image = image.to(device)\n",
    "\n",
    "            if use_image_aug: \n",
    "                image = img_augment(image)\n",
    "\n",
    "            clip_target = clip_img_embedder(image)\n",
    "            assert not torch.any(torch.isnan(clip_target))\n",
    "\n",
    "            if epoch < int(mixup_pct * num_epochs):\n",
    "                perm_list = [perm_iters[f\"subj0{s}_iter{train_i}\"].detach().to(device) for s in subj_list]\n",
    "                perm = torch.cat(perm_list, dim=0)\n",
    "                betas_list = [betas_iters[f\"subj0{s}_iter{train_i}\"].detach().to(device) for s in subj_list]\n",
    "                betas = torch.cat(betas_list, dim=0)\n",
    "                select_list = [select_iters[f\"subj0{s}_iter{train_i}\"].detach().to(device) for s in subj_list]\n",
    "                select = torch.cat(select_list, dim=0)\n",
    "\n",
    "            # voxel_ridge_list = [model.ridge(voxel_list[si],si) for si,s in enumerate(subj_list)]\n",
    "            # voxel_ridge = torch.cat(voxel_ridge_list, dim=0)\n",
    "            backbone, clip_voxels, blurry_image_enc_ = model.backbone(voxel_list[0])\n",
    "\n",
    "            if clip_scale>0:\n",
    "                clip_voxels_norm = nn.functional.normalize(clip_voxels.flatten(1), dim=-1)\n",
    "                clip_target_norm = nn.functional.normalize(clip_target.flatten(1), dim=-1)\n",
    "\n",
    "            if use_prior:\n",
    "                loss_prior, prior_out = model.diffusion_prior(text_embed=backbone, image_embed=clip_target)\n",
    "                loss_prior_total += loss_prior.item()\n",
    "                loss_prior *= prior_scale\n",
    "                loss += loss_prior\n",
    "\n",
    "                recon_cossim += nn.functional.cosine_similarity(prior_out, clip_target).mean().item()\n",
    "                recon_mse += mse(prior_out, clip_target).item()\n",
    "\n",
    "            if clip_scale>0:\n",
    "                if epoch < int(mixup_pct * num_epochs):                \n",
    "                    loss_clip = utils.mixco_nce(\n",
    "                        clip_voxels_norm,\n",
    "                        clip_target_norm,\n",
    "                        temp=.006,\n",
    "                        perm=perm, betas=betas, select=select)\n",
    "                else:\n",
    "                    epoch_temp = soft_loss_temps[epoch-int(mixup_pct*num_epochs)]\n",
    "                    loss_clip = utils.soft_clip_loss(\n",
    "                        clip_voxels_norm,\n",
    "                        clip_target_norm,\n",
    "                        temp=epoch_temp)\n",
    "\n",
    "                loss_clip_total += loss_clip.item()\n",
    "                loss_clip *= clip_scale\n",
    "                loss += loss_clip\n",
    "\n",
    "            if blurry_recon:     \n",
    "                image_enc_pred, transformer_feats = blurry_image_enc_\n",
    "\n",
    "                image_enc = autoenc.encode(2*image-1).latent_dist.mode() * 0.18215\n",
    "                loss_blurry = l1(image_enc_pred, image_enc)\n",
    "                loss_blurry_total += loss_blurry.item()\n",
    "\n",
    "                if epoch < int(mixup_pct * num_epochs):\n",
    "                    image_enc_shuf = image_enc[perm]\n",
    "                    betas_shape = [-1] + [1]*(len(image_enc.shape)-1)\n",
    "                    image_enc[select] = image_enc[select] * betas[select].reshape(*betas_shape) + \\\n",
    "                        image_enc_shuf[select] * (1 - betas[select]).reshape(*betas_shape)\n",
    "\n",
    "                image_norm = (image - mean)/std\n",
    "                image_aug = (blur_augs(image) - mean)/std\n",
    "                _, cnx_embeds = cnx(image_norm)\n",
    "                _, cnx_aug_embeds = cnx(image_aug)\n",
    "\n",
    "                cont_loss = utils.soft_cont_loss(\n",
    "                    nn.functional.normalize(transformer_feats.reshape(-1, transformer_feats.shape[-1]), dim=-1),\n",
    "                    nn.functional.normalize(cnx_embeds.reshape(-1, cnx_embeds.shape[-1]), dim=-1),\n",
    "                    nn.functional.normalize(cnx_aug_embeds.reshape(-1, cnx_embeds.shape[-1]), dim=-1),\n",
    "                    temp=0.2)\n",
    "                loss_blurry_cont_total += cont_loss.item()\n",
    "\n",
    "                loss += (loss_blurry + 0.1*cont_loss) * blur_scale #/.18215\n",
    "\n",
    "            if clip_scale>0:\n",
    "                # forward and backward top 1 accuracy        \n",
    "                labels = torch.arange(len(clip_voxels_norm)).to(clip_voxels_norm.device) \n",
    "                fwd_percent_correct += utils.topk(utils.batchwise_cosine_similarity(clip_voxels_norm, clip_target_norm), labels, k=1).item()\n",
    "                bwd_percent_correct += utils.topk(utils.batchwise_cosine_similarity(clip_target_norm, clip_voxels_norm), labels, k=1).item()\n",
    "\n",
    "            if blurry_recon:\n",
    "                with torch.no_grad():\n",
    "                    # only doing pixcorr eval on a subset of the samples per batch because its costly & slow to compute autoenc.decode()\n",
    "                    random_samps = np.random.choice(np.arange(len(image)), size=len(image)//5, replace=False)\n",
    "                    blurry_recon_images = (autoenc.decode(image_enc_pred[random_samps]/0.18215).sample/ 2 + 0.5).clamp(0,1)\n",
    "                    pixcorr = utils.pixcorr(image[random_samps], blurry_recon_images)\n",
    "                    blurry_pixcorr += pixcorr.item()\n",
    "\n",
    "            utils.check_loss(loss)\n",
    "            accelerator.backward(loss)\n",
    "            optimizer.step()\n",
    "\n",
    "            losses.append(loss.item())\n",
    "            lrs.append(optimizer.param_groups[0]['lr'])\n",
    "\n",
    "            if lr_scheduler_type is not None:\n",
    "                lr_scheduler.step()\n",
    "\n",
    "    model.eval()\n",
    "    if local_rank==0:\n",
    "        with torch.no_grad(), torch.cuda.amp.autocast(dtype=data_type): \n",
    "            for test_i, (behav, past_behav, future_behav, old_behav) in enumerate(test_dl):  \n",
    "                # all test samples should be loaded per batch such that test_i should never exceed 0\n",
    "                assert len(behav) == num_test\n",
    "\n",
    "                ## Average same-image repeats ##\n",
    "                if test_image is None:\n",
    "                    voxel = voxels[f'subj0{subj}'][behav[:,0,5].cpu().long()]\n",
    "                    \n",
    "                    if seq_len==1:\n",
    "                        voxel = voxel.unsqueeze(1)\n",
    "                    else:\n",
    "                        if seq_past>0:\n",
    "                            past_behavior = past_behav[:,:(seq_past),5].cpu().long()\n",
    "                            past_voxels = voxels[f'subj0{subj}'][past_behavior]\n",
    "                            if torch.any(past_behavior==-1).item(): # remove invalid voxels (-1 if there is no timepoint available)\n",
    "                                past_voxels[torch.where(past_behavior==-1)[0]] = 0\n",
    "\n",
    "                        if seq_future>0:\n",
    "                            future_behavior = future_behav[:,:(seq_future),5].cpu().long()\n",
    "                            future_voxels = voxels[f'subj0{subj}'][future_behavior]                    \n",
    "                            if torch.any(future_behavior==-1).item(): # remove invalid voxels (-1 if there is no timepoint available)\n",
    "                                future_voxels[torch.where(future_behavior==-1)[0]] = 0\n",
    "                            \n",
    "                        if seq_past > 0 and seq_future > 0:\n",
    "                            voxel = torch.cat((voxel.unsqueeze(1), past_voxels), axis=1)\n",
    "                            voxel = torch.cat((voxel, future_voxels), axis=1)\n",
    "                        elif seq_past > 0:\n",
    "                            voxel = torch.cat((voxel.unsqueeze(1), past_voxels), axis=1)\n",
    "                        else:\n",
    "                            voxel = torch.cat((voxel.unsqueeze(1), future_voxels), axis=1)\n",
    "\n",
    "                    image = behav[:,0,0].cpu().long()\n",
    "\n",
    "                    unique_image, sort_indices = torch.unique(image, return_inverse=True)\n",
    "                    for im in unique_image:\n",
    "                        locs = torch.where(im == image)[0]\n",
    "                        if len(locs)==1:\n",
    "                            locs = locs.repeat(3)\n",
    "                        elif len(locs)==2:\n",
    "                            locs = locs.repeat(2)[:3]\n",
    "                        assert len(locs)==3\n",
    "                        if test_image is None:\n",
    "                            test_image = images[im][None]\n",
    "                            test_voxel = voxel[locs][None]\n",
    "                        else:\n",
    "                            test_image = torch.vstack((test_image, images[im][None]))\n",
    "                            test_voxel = torch.vstack((test_voxel, voxel[locs][None]))\n",
    "\n",
    "                loss=0.\n",
    "                            \n",
    "                test_indices = torch.arange(len(test_voxel))[:300]\n",
    "                voxel = test_voxel[test_indices].to(device)\n",
    "                image = test_image[test_indices].to(device)\n",
    "                assert len(image) == 300\n",
    "\n",
    "                clip_target = clip_img_embedder(image.float())\n",
    "\n",
    "                for rep in range(3):\n",
    "                    # voxel_ridge = model.ridge(voxel[:,rep],0) # 0th index of subj_list\n",
    "                    backbone0, clip_voxels0, blurry_image_enc_ = model.backbone(voxel[:,rep])\n",
    "                    if rep==0:\n",
    "                        clip_voxels = clip_voxels0\n",
    "                        backbone = backbone0\n",
    "                    else:\n",
    "                        clip_voxels += clip_voxels0\n",
    "                        backbone += backbone0\n",
    "                clip_voxels /= 3\n",
    "                backbone /= 3\n",
    "\n",
    "                if clip_scale>0:\n",
    "                    clip_voxels_norm = nn.functional.normalize(clip_voxels.flatten(1), dim=-1)\n",
    "                    clip_target_norm = nn.functional.normalize(clip_target.flatten(1), dim=-1)\n",
    "                \n",
    "                # for some evals, only doing a subset of the samples per batch because of computational cost\n",
    "                random_samps = np.random.choice(np.arange(len(image)), size=len(image)//5, replace=False)\n",
    "                \n",
    "                if use_prior:\n",
    "                    loss_prior, contaminated_prior_out = model.diffusion_prior(text_embed=backbone[random_samps], image_embed=clip_target[random_samps])\n",
    "                    test_loss_prior_total += loss_prior.item()\n",
    "                    loss_prior *= prior_scale\n",
    "                    loss += loss_prior\n",
    "                    \n",
    "                    if visualize_prior:\n",
    "                        # now get unCLIP prediction without feeding it the image embed to get uncontaminated reconstruction\n",
    "                        prior_out = model.diffusion_prior.p_sample_loop(backbone[random_samps].shape, \n",
    "                                        text_cond = dict(text_embed = backbone[random_samps]), \n",
    "                                        cond_scale = 1., timesteps = timesteps)\n",
    "\n",
    "                        test_recon_cossim += nn.functional.cosine_similarity(prior_out, clip_target[random_samps]).mean().item()\n",
    "                        test_recon_mse += mse(prior_out, clip_target[random_samps]).item()\n",
    "                        \n",
    "                if clip_scale>0:\n",
    "                    loss_clip = utils.soft_clip_loss(\n",
    "                        clip_voxels_norm,\n",
    "                        clip_target_norm,\n",
    "                        temp=.006)\n",
    "\n",
    "                    test_loss_clip_total += loss_clip.item()\n",
    "                    loss_clip = loss_clip * clip_scale\n",
    "                    loss += loss_clip\n",
    "\n",
    "                if blurry_recon:\n",
    "                    image_enc_pred, _ = blurry_image_enc_\n",
    "                    blurry_recon_images = (autoenc.decode(image_enc_pred[random_samps]/0.18215).sample / 2 + 0.5).clamp(0,1)\n",
    "                    pixcorr = utils.pixcorr(image[random_samps], blurry_recon_images)\n",
    "                    test_blurry_pixcorr += pixcorr.item()\n",
    "\n",
    "                if clip_scale>0:\n",
    "                    # forward and backward top 1 accuracy        \n",
    "                    labels = torch.arange(len(clip_voxels_norm)).to(clip_voxels_norm.device) \n",
    "                    test_fwd_percent_correct += utils.topk(utils.batchwise_cosine_similarity(clip_voxels_norm, clip_target_norm), labels, k=1).item()\n",
    "                    test_bwd_percent_correct += utils.topk(utils.batchwise_cosine_similarity(clip_target_norm, clip_voxels_norm), labels, k=1).item()\n",
    "                \n",
    "                utils.check_loss(loss)                \n",
    "                test_losses.append(loss.item())\n",
    "\n",
    "            # if utils.is_interactive(): clear_output(wait=True)\n",
    "            print(\"---\")\n",
    "\n",
    "            assert (test_i+1) == 1\n",
    "            logs = {\"train/loss\": np.mean(losses[-(train_i+1):]),\n",
    "                \"test/loss\": np.mean(test_losses[-(test_i+1):]),\n",
    "                \"train/lr\": lrs[-1],\n",
    "                \"train/num_steps\": len(losses),\n",
    "                \"test/num_steps\": len(test_losses),\n",
    "                \"train/fwd_pct_correct\": fwd_percent_correct / (train_i + 1),\n",
    "                \"train/bwd_pct_correct\": bwd_percent_correct / (train_i + 1),\n",
    "                \"test/test_fwd_pct_correct\": test_fwd_percent_correct / (test_i + 1),\n",
    "                \"test/test_bwd_pct_correct\": test_bwd_percent_correct / (test_i + 1),\n",
    "                \"train/loss_clip_total\": loss_clip_total / (train_i + 1),\n",
    "                \"train/loss_blurry_total\": loss_blurry_total / (train_i + 1),\n",
    "                \"train/loss_blurry_cont_total\": loss_blurry_cont_total / (train_i + 1),\n",
    "                \"test/loss_clip_total\": test_loss_clip_total / (test_i + 1),\n",
    "                \"train/blurry_pixcorr\": blurry_pixcorr / (train_i + 1),\n",
    "                \"test/blurry_pixcorr\": test_blurry_pixcorr / (test_i + 1),\n",
    "                \"train/recon_cossim\": recon_cossim / (train_i + 1),\n",
    "                \"test/recon_cossim\": test_recon_cossim / (test_i + 1),\n",
    "                \"train/recon_mse\": recon_mse / (train_i + 1),\n",
    "                \"test/recon_mse\": test_recon_mse / (test_i + 1),\n",
    "                \"train/loss_prior\": loss_prior_total / (train_i + 1),\n",
    "                \"test/loss_prior\": test_loss_prior_total / (test_i + 1),\n",
    "                }\n",
    "\n",
    "            # if finished training, save jpg recons if they exist\n",
    "            if (epoch == num_epochs-1) or (epoch % ckpt_interval == 0):\n",
    "                if blurry_recon:    \n",
    "                    image_enc = autoenc.encode(2*image[:4]-1).latent_dist.mode() * 0.18215\n",
    "                    # transform blurry recon latents to images and plot it\n",
    "                    fig, axes = plt.subplots(1, 8, figsize=(10, 4))\n",
    "                    jj=-1\n",
    "                    for j in [0,1,2,3]:\n",
    "                        jj+=1\n",
    "                        axes[jj].imshow(utils.torch_to_Image((autoenc.decode(image_enc[[j]]/0.18215).sample / 2 + 0.5).clamp(0,1)))\n",
    "                        axes[jj].axis('off')\n",
    "                        jj+=1\n",
    "                        axes[jj].imshow(utils.torch_to_Image((autoenc.decode(image_enc_pred[[j]]/0.18215).sample / 2 + 0.5).clamp(0,1)))\n",
    "                        axes[jj].axis('off')\n",
    "\n",
    "                    if wandb_log:\n",
    "                        logs[f\"test/blur_recons\"] = wandb.Image(fig, caption=f\"epoch{epoch:03d}\")\n",
    "                        plt.close()\n",
    "                    else:\n",
    "                        plt.show()\n",
    "                        \n",
    "                if use_prior and visualize_prior: # output recons every ckpt\n",
    "                    idx = np.random.randint(0, 3)\n",
    "                    print(f\"reconstructing... idx={idx}\")\n",
    "                    samples = utils.unclip_recon(prior_out[[idx]],\n",
    "                             diffusion_engine,\n",
    "                             vector_suffix)\n",
    "                    if wandb_log:\n",
    "                        logs[f\"test/orig\"] = wandb.Image(transforms.ToPILImage()(image[idx]),\n",
    "                                                           caption=f\"epoch{epoch:03d}\")\n",
    "                        logs[f\"test/recons\"] = wandb.Image(transforms.ToPILImage()(samples[0]),\n",
    "                                                           caption=f\"epoch{epoch:03d}\")\n",
    "                    if utils.is_interactive():\n",
    "                        plt.figure(figsize=(2,2))\n",
    "                        plt.imshow(transforms.ToPILImage()(image[idx]))\n",
    "                        plt.axis('off')\n",
    "                        plt.show()\n",
    "                        \n",
    "                        plt.figure(figsize=(2,2))\n",
    "                        plt.imshow(transforms.ToPILImage()(samples[0]))\n",
    "                        plt.axis('off')\n",
    "                        plt.show()\n",
    "\n",
    "            progress_bar.set_postfix(**logs)\n",
    "\n",
    "            if wandb_log: wandb.log(logs)\n",
    "            \n",
    "    # Save model checkpoint and reconstruct\n",
    "    if (ckpt_saving) and (epoch % ckpt_interval == 0):\n",
    "        save_ckpt(f'last')\n",
    "\n",
    "    # wait for other GPUs to catch up if needed\n",
    "    accelerator.wait_for_everyone()\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "\n",
    "print(\"\\n===Finished!===\\n\")\n",
    "if ckpt_saving:\n",
    "    save_ckpt(f'brain-mlp')\n",
    "if not utils.is_interactive():\n",
    "    sys.exit(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e81ae3-171f-40ad-a3e8-24bee4472325",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.plot(losses)\n",
    "plt.show()\n",
    "plt.plot(test_losses)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fmri2",
   "language": "python",
   "name": "fmri2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "toc-autonumbering": true,
  "vscode": {
   "interpreter": {
    "hash": "62aae01ef0cf7b6af841ab1c8ce59175c4332e693ab3d00bc32ceffb78a35376"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
